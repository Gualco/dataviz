<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Resampling-based Statistical Assessment | Data Analysis and Visualization in R (IN2339)</title>
  <meta name="description" content="TODO This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Resampling-based Statistical Assessment | Data Analysis and Visualization in R (IN2339)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="TODO This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Resampling-based Statistical Assessment | Data Analysis and Visualization in R (IN2339)" />
  
  <meta name="twitter:description" content="TODO This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  



<meta name="date" content="2021-11-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="graph-supported-hypos.html"/>
<link rel="next" href="analytical-stat.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis and Visualization in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="feedback.html"><a href="feedback.html"><i class="fa fa-check"></i>Feedback</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#data-science-what-and-why"><i class="fa fa-check"></i>Data Science: What and why?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#what-you-will-learn-and-not-learn"><i class="fa fa-check"></i>What you will learn and not learn</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#the-r-language"><i class="fa fa-check"></i>The R language</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#course-overview"><i class="fa fa-check"></i>Course overview</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#complementary-reading"><i class="fa fa-check"></i>Complementary reading</a></li>
</ul></li>
<li class="part"><span><b>I Get</b></span></li>
<li class="chapter" data-level="1" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>1</b> R basics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-basics.html"><a href="r-basics.html#rstudio"><i class="fa fa-check"></i><b>1.1</b> Rstudio</a></li>
<li class="chapter" data-level="1.2" data-path="r-basics.html"><a href="r-basics.html#first-steps-with-r"><i class="fa fa-check"></i><b>1.2</b> First steps with R</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="r-basics.html"><a href="r-basics.html#objects"><i class="fa fa-check"></i><b>1.2.1</b> Objects</a></li>
<li class="chapter" data-level="1.2.2" data-path="r-basics.html"><a href="r-basics.html#the-workspace"><i class="fa fa-check"></i><b>1.2.2</b> The workspace</a></li>
<li class="chapter" data-level="1.2.3" data-path="r-basics.html"><a href="r-basics.html#functions"><i class="fa fa-check"></i><b>1.2.3</b> Functions</a></li>
<li class="chapter" data-level="1.2.4" data-path="r-basics.html"><a href="r-basics.html#other-prebuilt-objects"><i class="fa fa-check"></i><b>1.2.4</b> Other prebuilt objects</a></li>
<li class="chapter" data-level="1.2.5" data-path="r-basics.html"><a href="r-basics.html#variable-names"><i class="fa fa-check"></i><b>1.2.5</b> Variable names</a></li>
<li class="chapter" data-level="1.2.6" data-path="r-basics.html"><a href="r-basics.html#reusing-scripts"><i class="fa fa-check"></i><b>1.2.6</b> Reusing scripts</a></li>
<li class="chapter" data-level="1.2.7" data-path="r-basics.html"><a href="r-basics.html#commenting-your-code"><i class="fa fa-check"></i><b>1.2.7</b> Commenting your code</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="r-basics.html"><a href="r-basics.html#data-types"><i class="fa fa-check"></i><b>1.3</b> Data types</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="r-basics.html"><a href="r-basics.html#data-frames"><i class="fa fa-check"></i><b>1.3.1</b> Data frames</a></li>
<li class="chapter" data-level="1.3.2" data-path="r-basics.html"><a href="r-basics.html#examining-an-object"><i class="fa fa-check"></i><b>1.3.2</b> Examining an object</a></li>
<li class="chapter" data-level="1.3.3" data-path="r-basics.html"><a href="r-basics.html#the-accessor"><i class="fa fa-check"></i><b>1.3.3</b> The accessor: <code>$</code></a></li>
<li class="chapter" data-level="1.3.4" data-path="r-basics.html"><a href="r-basics.html#vectors-numerics-characters-and-logical"><i class="fa fa-check"></i><b>1.3.4</b> Vectors: numerics, characters, and logical</a></li>
<li class="chapter" data-level="1.3.5" data-path="r-basics.html"><a href="r-basics.html#factors"><i class="fa fa-check"></i><b>1.3.5</b> Factors</a></li>
<li class="chapter" data-level="1.3.6" data-path="r-basics.html"><a href="r-basics.html#lists"><i class="fa fa-check"></i><b>1.3.6</b> Lists</a></li>
<li class="chapter" data-level="1.3.7" data-path="r-basics.html"><a href="r-basics.html#matrices"><i class="fa fa-check"></i><b>1.3.7</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="r-basics.html"><a href="r-basics.html#vectors"><i class="fa fa-check"></i><b>1.4</b> Vectors</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="r-basics.html"><a href="r-basics.html#creating-vectors"><i class="fa fa-check"></i><b>1.4.1</b> Creating vectors</a></li>
<li class="chapter" data-level="1.4.2" data-path="r-basics.html"><a href="r-basics.html#names"><i class="fa fa-check"></i><b>1.4.2</b> Names</a></li>
<li class="chapter" data-level="1.4.3" data-path="r-basics.html"><a href="r-basics.html#sequences"><i class="fa fa-check"></i><b>1.4.3</b> Sequences</a></li>
<li class="chapter" data-level="1.4.4" data-path="r-basics.html"><a href="r-basics.html#subsetting"><i class="fa fa-check"></i><b>1.4.4</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="r-basics.html"><a href="r-basics.html#coercion"><i class="fa fa-check"></i><b>1.5</b> Coercion</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="r-basics.html"><a href="r-basics.html#not-availables-na"><i class="fa fa-check"></i><b>1.5.1</b> Not availables (NA)</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="r-basics.html"><a href="r-basics.html#sorting"><i class="fa fa-check"></i><b>1.6</b> Sorting</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="r-basics.html"><a href="r-basics.html#sort"><i class="fa fa-check"></i><b>1.6.1</b> <code>sort</code></a></li>
<li class="chapter" data-level="1.6.2" data-path="r-basics.html"><a href="r-basics.html#order"><i class="fa fa-check"></i><b>1.6.2</b> <code>order</code></a></li>
<li class="chapter" data-level="1.6.3" data-path="r-basics.html"><a href="r-basics.html#max-and-which.max"><i class="fa fa-check"></i><b>1.6.3</b> <code>max</code> and <code>which.max</code></a></li>
<li class="chapter" data-level="1.6.4" data-path="r-basics.html"><a href="r-basics.html#rank"><i class="fa fa-check"></i><b>1.6.4</b> <code>rank</code></a></li>
<li class="chapter" data-level="1.6.5" data-path="r-basics.html"><a href="r-basics.html#beware-of-recycling"><i class="fa fa-check"></i><b>1.6.5</b> Beware of recycling</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="r-basics.html"><a href="r-basics.html#vector-arithmetics"><i class="fa fa-check"></i><b>1.7</b> Vector arithmetics</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="r-basics.html"><a href="r-basics.html#rescaling-a-vector"><i class="fa fa-check"></i><b>1.7.1</b> Rescaling a vector</a></li>
<li class="chapter" data-level="1.7.2" data-path="r-basics.html"><a href="r-basics.html#two-vectors"><i class="fa fa-check"></i><b>1.7.2</b> Two vectors</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="r-basics.html"><a href="r-basics.html#indexing"><i class="fa fa-check"></i><b>1.8</b> Indexing</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="r-basics.html"><a href="r-basics.html#subsetting-with-logicals"><i class="fa fa-check"></i><b>1.8.1</b> Subsetting with logicals</a></li>
<li class="chapter" data-level="1.8.2" data-path="r-basics.html"><a href="r-basics.html#logical-operators"><i class="fa fa-check"></i><b>1.8.2</b> Logical operators</a></li>
<li class="chapter" data-level="1.8.3" data-path="r-basics.html"><a href="r-basics.html#which"><i class="fa fa-check"></i><b>1.8.3</b> <code>which</code></a></li>
<li class="chapter" data-level="1.8.4" data-path="r-basics.html"><a href="r-basics.html#match"><i class="fa fa-check"></i><b>1.8.4</b> <code>match</code></a></li>
<li class="chapter" data-level="1.8.5" data-path="r-basics.html"><a href="r-basics.html#in"><i class="fa fa-check"></i><b>1.8.5</b> <code>%in%</code></a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="r-basics.html"><a href="r-basics.html#r-programming"><i class="fa fa-check"></i><b>1.9</b> R programming</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>2</b> Data wrangling</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-wrangling.html"><a href="data-wrangling.html#data.tables"><i class="fa fa-check"></i><b>2.1</b> Data.tables</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="data-wrangling.html"><a href="data-wrangling.html#overview"><i class="fa fa-check"></i><b>2.1.1</b> Overview</a></li>
<li class="chapter" data-level="2.1.2" data-path="data-wrangling.html"><a href="data-wrangling.html#creating-and-loading-tables"><i class="fa fa-check"></i><b>2.1.2</b> Creating and loading tables</a></li>
<li class="chapter" data-level="2.1.3" data-path="data-wrangling.html"><a href="data-wrangling.html#inspecting-tables"><i class="fa fa-check"></i><b>2.1.3</b> Inspecting tables</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-wrangling.html"><a href="data-wrangling.html#row-subsetting"><i class="fa fa-check"></i><b>2.2</b> Row subsetting</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="data-wrangling.html"><a href="data-wrangling.html#subsetting-rows-by-indices"><i class="fa fa-check"></i><b>2.2.1</b> Subsetting rows by indices</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-wrangling.html"><a href="data-wrangling.html#subsetting-rows-by-logical-conditions"><i class="fa fa-check"></i><b>2.2.2</b> Subsetting rows by logical conditions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-wrangling.html"><a href="data-wrangling.html#column-operations"><i class="fa fa-check"></i><b>2.3</b> Column operations</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="data-wrangling.html"><a href="data-wrangling.html#working-with-columns"><i class="fa fa-check"></i><b>2.3.1</b> Working with columns</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-wrangling.html"><a href="data-wrangling.html#column-operations-1"><i class="fa fa-check"></i><b>2.3.2</b> Column operations</a></li>
<li class="chapter" data-level="2.3.3" data-path="data-wrangling.html"><a href="data-wrangling.html#advanced-commands-apply-over-columns"><i class="fa fa-check"></i><b>2.3.3</b> Advanced commands: *apply() over columns</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="data-wrangling.html"><a href="data-wrangling.html#the-by-option"><i class="fa fa-check"></i><b>2.4</b> The ‘by’ option</a></li>
<li class="chapter" data-level="2.5" data-path="data-wrangling.html"><a href="data-wrangling.html#counting-occurences-with-.n"><i class="fa fa-check"></i><b>2.5</b> Counting occurences with <code>.N</code></a></li>
<li class="chapter" data-level="2.6" data-path="data-wrangling.html"><a href="data-wrangling.html#extending-tables"><i class="fa fa-check"></i><b>2.6</b> Extending tables</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="data-wrangling.html"><a href="data-wrangling.html#creating-new-columns-the-command"><i class="fa fa-check"></i><b>2.6.1</b> Creating new columns (the := command)</a></li>
<li class="chapter" data-level="2.6.2" data-path="data-wrangling.html"><a href="data-wrangling.html#advanced-multiple-assignments"><i class="fa fa-check"></i><b>2.6.2</b> Advanced: Multiple assignments</a></li>
<li class="chapter" data-level="2.6.3" data-path="data-wrangling.html"><a href="data-wrangling.html#copying-tables"><i class="fa fa-check"></i><b>2.6.3</b> Copying tables</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="data-wrangling.html"><a href="data-wrangling.html#summary"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="data-wrangling.html"><a href="data-wrangling.html#data.table-resources"><i class="fa fa-check"></i><b>2.8</b> Data.table resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html"><i class="fa fa-check"></i><b>3</b> Tidy data and combining tables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#motivation"><i class="fa fa-check"></i><b>3.1.1</b> Motivation</a></li>
<li class="chapter" data-level="3.1.2" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#datasets-used-in-this-chapter"><i class="fa fa-check"></i><b>3.1.2</b> Datasets used in this chapter</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#tidy-and-untidy-data"><i class="fa fa-check"></i><b>3.2</b> Tidy and untidy data</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>3.2.1</b> Definition of tidy data</a></li>
<li class="chapter" data-level="3.2.2" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#advantages-of-tidy-data"><i class="fa fa-check"></i><b>3.2.2</b> Advantages of tidy data</a></li>
<li class="chapter" data-level="3.2.3" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#common-signs-of-untidy-datasets"><i class="fa fa-check"></i><b>3.2.3</b> Common signs of untidy datasets</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#tidying-up-datasets"><i class="fa fa-check"></i><b>3.3</b> Tidying up datasets</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#melting-wide-to-long"><i class="fa fa-check"></i><b>3.3.1</b> Melting (wide to long)</a></li>
<li class="chapter" data-level="3.3.2" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#casting-long-to-wide"><i class="fa fa-check"></i><b>3.3.2</b> Casting (long to wide)</a></li>
<li class="chapter" data-level="3.3.3" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#separating-columns"><i class="fa fa-check"></i><b>3.3.3</b> Separating columns</a></li>
<li class="chapter" data-level="3.3.4" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#uniting-columns"><i class="fa fa-check"></i><b>3.3.4</b> Uniting columns</a></li>
<li class="chapter" data-level="3.3.5" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#advanced-columns-containing-sets-of-values"><i class="fa fa-check"></i><b>3.3.5</b> Advanced: Columns containing sets of values</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#concatenating-tables"><i class="fa fa-check"></i><b>3.4</b> Concatenating tables</a></li>
<li class="chapter" data-level="3.5" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#merging-tables"><i class="fa fa-check"></i><b>3.5</b> Merging tables</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#inner-merge"><i class="fa fa-check"></i><b>3.5.1</b> Inner merge</a></li>
<li class="chapter" data-level="3.5.2" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#outer-full-merge"><i class="fa fa-check"></i><b>3.5.2</b> Outer (full) merge</a></li>
<li class="chapter" data-level="3.5.3" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#left-merge"><i class="fa fa-check"></i><b>3.5.3</b> Left merge</a></li>
<li class="chapter" data-level="3.5.4" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#right-merge"><i class="fa fa-check"></i><b>3.5.4</b> Right merge</a></li>
<li class="chapter" data-level="3.5.5" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#merging-by-several-columns"><i class="fa fa-check"></i><b>3.5.5</b> Merging by several columns</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#tidy-not-unique"><i class="fa fa-check"></i><b>3.6</b> Tidy representations are not unique</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#alternative-tidy-forms-of-a-table"><i class="fa fa-check"></i><b>3.6.1</b> Alternative tidy forms of a table</a></li>
<li class="chapter" data-level="3.6.2" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#on-multiple-types-of-observational-units-in-the-same-table"><i class="fa fa-check"></i><b>3.6.2</b> On multiple types of observational units in the same table</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#summary-1"><i class="fa fa-check"></i><b>3.7</b> Summary</a></li>
<li class="chapter" data-level="3.8" data-path="tidy-data-and-combining-tables.html"><a href="tidy-data-and-combining-tables.html#tidy-data-resources"><i class="fa fa-check"></i><b>3.8</b> Tidy data resources</a></li>
</ul></li>
<li class="part"><span><b>II Look</b></span></li>
<li class="chapter" data-level="4" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html"><i class="fa fa-check"></i><b>4</b> Low dimensional visualizations</a>
<ul>
<li class="chapter" data-level="4.1" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#why-plotting"><i class="fa fa-check"></i><b>4.1</b> Why plotting?</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#plot-vs-stat"><i class="fa fa-check"></i><b>4.1.1</b> Plotting versus summary statistics</a></li>
<li class="chapter" data-level="4.1.2" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#plot-debug"><i class="fa fa-check"></i><b>4.1.2</b> Plotting helps finding bugs in the data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#grammar-of-graphics"><i class="fa fa-check"></i><b>4.2</b> Grammar of graphics</a></li>
<li class="chapter" data-level="4.3" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#components-of-the-layered-grammar"><i class="fa fa-check"></i><b>4.3</b> Components of the layered grammar</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#components-of-the-grammar-of-graphics"><i class="fa fa-check"></i><b>4.3.1</b> Components of the grammar of graphics</a></li>
<li class="chapter" data-level="4.3.2" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#defining-the-data-and-layers"><i class="fa fa-check"></i><b>4.3.2</b> Defining the data and layers</a></li>
<li class="chapter" data-level="4.3.3" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#mapping-of-aesthetics"><i class="fa fa-check"></i><b>4.3.3</b> Mapping of aesthetics</a></li>
<li class="chapter" data-level="4.3.4" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#facets-axes-and-labels"><i class="fa fa-check"></i><b>4.3.4</b> Facets, axes and labels</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#different-types-of-one--and-two-dimensional-plots"><i class="fa fa-check"></i><b>4.4</b> Different types of one- and two-dimensional plots</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#plots-for-one-single-continuous-variable"><i class="fa fa-check"></i><b>4.4.1</b> Plots for one single continuous variable</a></li>
<li class="chapter" data-level="4.4.2" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#plots-for-two-variables-one-continuous-one-discrete"><i class="fa fa-check"></i><b>4.4.2</b> Plots for two variables: one continuous, one discrete</a></li>
<li class="chapter" data-level="4.4.3" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#plots-for-two-continuos-variables"><i class="fa fa-check"></i><b>4.4.3</b> Plots for two continuos variables</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#further-plots-for-low-dimensional-data"><i class="fa fa-check"></i><b>4.5</b> Further plots for low dimensional data</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#plot-matrix"><i class="fa fa-check"></i><b>4.5.1</b> Plot matrix</a></li>
<li class="chapter" data-level="4.5.2" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#correlation-plot"><i class="fa fa-check"></i><b>4.5.2</b> Correlation plot</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#summary-2"><i class="fa fa-check"></i><b>4.6</b> Summary</a></li>
<li class="chapter" data-level="4.7" data-path="low-dimensional-visualizations.html"><a href="low-dimensional-visualizations.html#resources"><i class="fa fa-check"></i><b>4.7</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html"><i class="fa fa-check"></i><b>5</b> High dimensional visualizations</a>
<ul>
<li class="chapter" data-level="5.1" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#notations"><i class="fa fa-check"></i><b>5.1</b> Notations</a></li>
<li class="chapter" data-level="5.2" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#data-matrix-preparation"><i class="fa fa-check"></i><b>5.2</b> Data matrix preparation</a></li>
<li class="chapter" data-level="5.3" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#heatmaps"><i class="fa fa-check"></i><b>5.3</b> Heatmaps</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#centering-and-scaling-variables"><i class="fa fa-check"></i><b>5.3.1</b> Centering and scaling variables</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#clustering"><i class="fa fa-check"></i><b>5.4</b> Clustering</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#k-means-clustering"><i class="fa fa-check"></i><b>5.4.1</b> K-Means clustering</a></li>
<li class="chapter" data-level="5.4.2" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#hclust"><i class="fa fa-check"></i><b>5.4.2</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="5.4.3" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#comparing-clusterings-with-the-rand-index"><i class="fa fa-check"></i><b>5.4.3</b> Comparing clusterings with the Rand index</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#dimensionality-reduction-with-pca"><i class="fa fa-check"></i><b>5.5</b> Dimensionality reduction with PCA</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#a-minimal-pca-from-2d-to-1d"><i class="fa fa-check"></i><b>5.5.1</b> A minimal PCA: From 2D to 1D</a></li>
<li class="chapter" data-level="5.5.2" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#pca-in-higher-dimensions"><i class="fa fa-check"></i><b>5.5.2</b> PCA in higher dimensions</a></li>
<li class="chapter" data-level="5.5.3" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#pca-in-r"><i class="fa fa-check"></i><b>5.5.3</b> PCA in R</a></li>
<li class="chapter" data-level="5.5.4" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#plotting-pca-results-in-r"><i class="fa fa-check"></i><b>5.5.4</b> Plotting PCA results in R</a></li>
<li class="chapter" data-level="5.5.5" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#pca-summary"><i class="fa fa-check"></i><b>5.5.5</b> PCA summary</a></li>
<li class="chapter" data-level="5.5.6" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#nonlinear-dimension-reduction"><i class="fa fa-check"></i><b>5.5.6</b> Nonlinear dimension reduction</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#discussion"><i class="fa fa-check"></i><b>5.6</b> Discussion</a></li>
<li class="chapter" data-level="5.7" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#summary-3"><i class="fa fa-check"></i><b>5.7</b> Summary</a></li>
<li class="chapter" data-level="5.8" data-path="high-dimensional-visualizations.html"><a href="high-dimensional-visualizations.html#resources-1"><i class="fa fa-check"></i><b>5.8</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html"><i class="fa fa-check"></i><b>6</b> Graphically supported hypotheses</a>
<ul>
<li class="chapter" data-level="6.1" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#descriptive-vs.-associative-plots"><i class="fa fa-check"></i><b>6.1</b> Descriptive vs. associative plots</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#descriptive-plots"><i class="fa fa-check"></i><b>6.1.1</b> Descriptive plots</a></li>
<li class="chapter" data-level="6.1.2" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#associative-plots"><i class="fa fa-check"></i><b>6.1.2</b> Associative plots</a></li>
<li class="chapter" data-level="6.1.3" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#correctly-using-descriptive-and-demonstrative-plots"><i class="fa fa-check"></i><b>6.1.3</b> Correctly using descriptive and demonstrative plots</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#correlation-and-causation"><i class="fa fa-check"></i><b>6.2</b> Correlation and causation</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#the-association-is-not-statistically-supported"><i class="fa fa-check"></i><b>6.2.1</b> The association is not statistically supported</a></li>
<li class="chapter" data-level="6.2.2" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#reversing-cause-and-effect"><i class="fa fa-check"></i><b>6.2.2</b> Reversing cause and effect</a></li>
<li class="chapter" data-level="6.2.3" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#the-association-is-induced-by-a-third-variable"><i class="fa fa-check"></i><b>6.2.3</b> The association is induced by a third variable</a></li>
<li class="chapter" data-level="6.2.4" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#simpsons-paradox"><i class="fa fa-check"></i><b>6.2.4</b> Simpson’s paradox</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#data-presentation-as-story-telling"><i class="fa fa-check"></i><b>6.3</b> Data presentation as story telling</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#what-is-a-story"><i class="fa fa-check"></i><b>6.3.1</b> What is a story?</a></li>
<li class="chapter" data-level="6.3.2" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#presentation-structure"><i class="fa fa-check"></i><b>6.3.2</b> Presentation structure</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#guidelines-for-coloring-in-data-visualization"><i class="fa fa-check"></i><b>6.4</b> Guidelines for coloring in data visualization</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#color-coding-in-r"><i class="fa fa-check"></i><b>6.4.1</b> Color coding in R</a></li>
<li class="chapter" data-level="6.4.2" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#general-rules-for-color-coding"><i class="fa fa-check"></i><b>6.4.2</b> General rules for color coding</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#general-dos-and-donts-in-data-visualization"><i class="fa fa-check"></i><b>6.5</b> General do’s and don’ts in data visualization</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#dos"><i class="fa fa-check"></i><b>6.5.1</b> Do’s</a></li>
<li class="chapter" data-level="6.5.2" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#donts"><i class="fa fa-check"></i><b>6.5.2</b> don’ts</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#summary-4"><i class="fa fa-check"></i><b>6.6</b> Summary</a></li>
<li class="chapter" data-level="6.7" data-path="graph-supported-hypos.html"><a href="graph-supported-hypos.html#resources-2"><i class="fa fa-check"></i><b>6.7</b> Resources</a></li>
</ul></li>
<li class="part"><span><b>III Conclude</b></span></li>
<li class="chapter" data-level="7" data-path="resampling-stat.html"><a href="resampling-stat.html"><i class="fa fa-check"></i><b>7</b> Resampling-based Statistical Assessment</a>
<ul>
<li class="chapter" data-level="7.1" data-path="resampling-stat.html"><a href="resampling-stat.html#yeast-dataset"><i class="fa fa-check"></i><b>7.1</b> The yeast dataset</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="resampling-stat.html"><a href="resampling-stat.html#the-experiment"><i class="fa fa-check"></i><b>7.1.1</b> The experiment</a></li>
<li class="chapter" data-level="7.1.2" data-path="resampling-stat.html"><a href="resampling-stat.html#genotype"><i class="fa fa-check"></i><b>7.1.2</b> Genotype</a></li>
<li class="chapter" data-level="7.1.3" data-path="resampling-stat.html"><a href="resampling-stat.html#growth-rates"><i class="fa fa-check"></i><b>7.1.3</b> Growth rates</a></li>
<li class="chapter" data-level="7.1.4" data-path="resampling-stat.html"><a href="resampling-stat.html#genotype-growth-rate-association-in-maltose-at-a-specific-marker"><i class="fa fa-check"></i><b>7.1.4</b> Genotype-growth rate association in maltose at a specific marker</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="resampling-stat.html"><a href="resampling-stat.html#statistical-hypothesis-testing"><i class="fa fa-check"></i><b>7.2</b> Statistical hypothesis testing</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="resampling-stat.html"><a href="resampling-stat.html#permut-test-build-up"><i class="fa fa-check"></i><b>7.2.1</b> Permutation testing: An intuitive build-up</a></li>
<li class="chapter" data-level="7.2.2" data-path="resampling-stat.html"><a href="resampling-stat.html#concepts-of-statistical-hypothesis-testing"><i class="fa fa-check"></i><b>7.2.2</b> Concepts of Statistical Hypothesis Testing</a></li>
<li class="chapter" data-level="7.2.3" data-path="resampling-stat.html"><a href="resampling-stat.html#permutation-testing-formally"><i class="fa fa-check"></i><b>7.2.3</b> Permutation testing, formally</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="resampling-stat.html"><a href="resampling-stat.html#confidence-intervals-quantifying-uncertainty-in-parameter-estimates"><i class="fa fa-check"></i><b>7.3</b> Confidence intervals: Quantifying uncertainty in parameter estimates</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="resampling-stat.html"><a href="resampling-stat.html#repeating-experiments-to-quantify-uncertainty"><i class="fa fa-check"></i><b>7.3.1</b> Repeating experiments to quantify uncertainty</a></li>
<li class="chapter" data-level="7.3.2" data-path="resampling-stat.html"><a href="resampling-stat.html#simulating-repeated-experiments"><i class="fa fa-check"></i><b>7.3.2</b> Simulating repeated experiments</a></li>
<li class="chapter" data-level="7.3.3" data-path="resampling-stat.html"><a href="resampling-stat.html#quantifying-uncertainty-using-the-case-resampling-bootstrap"><i class="fa fa-check"></i><b>7.3.3</b> Quantifying uncertainty using the case resampling bootstrap</a></li>
<li class="chapter" data-level="7.3.4" data-path="resampling-stat.html"><a href="resampling-stat.html#confidence-intervals-formal-definition"><i class="fa fa-check"></i><b>7.3.4</b> Confidence Intervals: Formal definition</a></li>
<li class="chapter" data-level="7.3.5" data-path="resampling-stat.html"><a href="resampling-stat.html#visualizing-the-formal-definition-of-confidence-intervals"><i class="fa fa-check"></i><b>7.3.5</b> Visualizing the formal definition of Confidence Intervals</a></li>
<li class="chapter" data-level="7.3.6" data-path="resampling-stat.html"><a href="resampling-stat.html#hypothesis-testing-with-the-confidence-interval"><i class="fa fa-check"></i><b>7.3.6</b> Hypothesis testing with the Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="resampling-stat.html"><a href="resampling-stat.html#discussion-1"><i class="fa fa-check"></i><b>7.4</b> Discussion</a></li>
<li class="chapter" data-level="7.5" data-path="resampling-stat.html"><a href="resampling-stat.html#conclusion"><i class="fa fa-check"></i><b>7.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="analytical-stat.html"><a href="analytical-stat.html"><i class="fa fa-check"></i><b>8</b> Analytical Statistical Assessment</a>
<ul>
<li class="chapter" data-level="8.1" data-path="analytical-stat.html"><a href="analytical-stat.html#motivation-hypothesis-testing-in-large-datasets"><i class="fa fa-check"></i><b>8.1</b> Motivation: Hypothesis testing in large datasets</a></li>
<li class="chapter" data-level="8.2" data-path="analytical-stat.html"><a href="analytical-stat.html#the-binomial-test-testing-hypotheses-for-a-single-binary-variable"><i class="fa fa-check"></i><b>8.2</b> The Binomial Test: testing hypotheses for a single binary variable</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="analytical-stat.html"><a href="analytical-stat.html#abstraction-tossing-a-coin"><i class="fa fa-check"></i><b>8.2.1</b> Abstraction: Tossing a coin</a></li>
<li class="chapter" data-level="8.2.2" data-path="analytical-stat.html"><a href="analytical-stat.html#computing-a-binomial-test-with-r"><i class="fa fa-check"></i><b>8.2.2</b> Computing a binomial test with R</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="analytical-stat.html"><a href="analytical-stat.html#fisher-test"><i class="fa fa-check"></i><b>8.3</b> Fisher’s exact test: Testing the association between two binary variables</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="analytical-stat.html"><a href="analytical-stat.html#permutation-testing-and-the-hypergeometric-distribution"><i class="fa fa-check"></i><b>8.3.1</b> Permutation testing and the hypergeometric distribution</a></li>
<li class="chapter" data-level="8.3.2" data-path="analytical-stat.html"><a href="analytical-stat.html#fishers-exact-test"><i class="fa fa-check"></i><b>8.3.2</b> Fisher’s exact test</a></li>
<li class="chapter" data-level="8.3.3" data-path="analytical-stat.html"><a href="analytical-stat.html#fishers-exact-test-in-r"><i class="fa fa-check"></i><b>8.3.3</b> Fisher’s exact test in R</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="analytical-stat.html"><a href="analytical-stat.html#testing-the-association-between-one-quantitative-and-one-binary-variable"><i class="fa fa-check"></i><b>8.4</b> Testing the association between one quantitative and one binary variable</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="analytical-stat.html"><a href="analytical-stat.html#the-t-test"><i class="fa fa-check"></i><b>8.4.1</b> The t-test</a></li>
<li class="chapter" data-level="8.4.2" data-path="analytical-stat.html"><a href="analytical-stat.html#wilcoxon-rank-sum-test-an-alternative-to-the-t-test-for-non-gaussian-data"><i class="fa fa-check"></i><b>8.4.2</b> Wilcoxon rank-sum test: An alternative to the t-test for non-Gaussian data</a></li>
<li class="chapter" data-level="8.4.3" data-path="analytical-stat.html"><a href="analytical-stat.html#why-bother-with-the-wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>8.4.3</b> Why bother with the Wilcoxon rank-sum test?</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="analytical-stat.html"><a href="analytical-stat.html#association-between-two-quantitative-variables"><i class="fa fa-check"></i><b>8.5</b> Association between two quantitative variables</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="analytical-stat.html"><a href="analytical-stat.html#the-pearson-correlation-test"><i class="fa fa-check"></i><b>8.5.1</b> The Pearson correlation test</a></li>
<li class="chapter" data-level="8.5.2" data-path="analytical-stat.html"><a href="analytical-stat.html#the-spearman-rank-correlation-test"><i class="fa fa-check"></i><b>8.5.2</b> The Spearman rank correlation test</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="analytical-stat.html"><a href="analytical-stat.html#testing-associations-of-two-variables-overview"><i class="fa fa-check"></i><b>8.6</b> Testing associations of two variables: Overview</a></li>
<li class="chapter" data-level="8.7" data-path="analytical-stat.html"><a href="analytical-stat.html#assessing-distributional-assumptions-with-q-q-plots"><i class="fa fa-check"></i><b>8.7</b> Assessing distributional assumptions with Q-Q Plots</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="analytical-stat.html"><a href="analytical-stat.html#limitations-of-histograms"><i class="fa fa-check"></i><b>8.7.1</b> Limitations of Histograms</a></li>
<li class="chapter" data-level="8.7.2" data-path="analytical-stat.html"><a href="analytical-stat.html#q-q-plots-comparing-empirical-to-theoretical-quantiles"><i class="fa fa-check"></i><b>8.7.2</b> Q-Q plots: Comparing empirical to theoretical quantiles</a></li>
<li class="chapter" data-level="8.7.3" data-path="analytical-stat.html"><a href="analytical-stat.html#typical-q-q-plots"><i class="fa fa-check"></i><b>8.7.3</b> Typical Q-Q plots</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="analytical-stat.html"><a href="analytical-stat.html#analytical-conf-int"><i class="fa fa-check"></i><b>8.8</b> Analytical Confidence intervals</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="analytical-stat.html"><a href="analytical-stat.html#binomial-case"><i class="fa fa-check"></i><b>8.8.1</b> Binomial case</a></li>
<li class="chapter" data-level="8.8.2" data-path="analytical-stat.html"><a href="analytical-stat.html#confidence-intervals-in-r"><i class="fa fa-check"></i><b>8.8.2</b> Confidence intervals in R</a></li>
<li class="chapter" data-level="8.8.3" data-path="analytical-stat.html"><a href="analytical-stat.html#advanced-a-note-on-overlapping-confidence-intervals"><i class="fa fa-check"></i><b>8.8.3</b> Advanced: A note on overlapping confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="analytical-stat.html"><a href="analytical-stat.html#discussion-2"><i class="fa fa-check"></i><b>8.9</b> Discussion</a></li>
<li class="chapter" data-level="8.10" data-path="analytical-stat.html"><a href="analytical-stat.html#conclusion-1"><i class="fa fa-check"></i><b>8.10</b> Conclusion</a></li>
<li class="chapter" data-level="8.11" data-path="analytical-stat.html"><a href="analytical-stat.html#resources-3"><i class="fa fa-check"></i><b>8.11</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-data-stat.html"><a href="big-data-stat.html"><i class="fa fa-check"></i><b>9</b> Statistical Assessments for Big Data</a>
<ul>
<li class="chapter" data-level="9.1" data-path="big-data-stat.html"><a href="big-data-stat.html#motivation-statistical-significance-in-a-big-data-context"><i class="fa fa-check"></i><b>9.1</b> Motivation: Statistical Significance in a Big Data context</a></li>
<li class="chapter" data-level="9.2" data-path="big-data-stat.html"><a href="big-data-stat.html#effect-size-actually-important-or-just-significant"><i class="fa fa-check"></i><b>9.2</b> Effect Size: Actually important or just significant?</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="big-data-stat.html"><a href="big-data-stat.html#the-relationship-of-sample-size-and-significance"><i class="fa fa-check"></i><b>9.2.1</b> The relationship of sample size and significance</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-data-stat.html"><a href="big-data-stat.html#report-p-value-effect-size-and-plot"><i class="fa fa-check"></i><b>9.2.2</b> Report P-value, effect size, and plot</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="big-data-stat.html"><a href="big-data-stat.html#multiple-testing"><i class="fa fa-check"></i><b>9.3</b> Multiple Testing</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="big-data-stat.html"><a href="big-data-stat.html#multiple-testing-in-real-life-p-hacking-and-fishing-expeditions"><i class="fa fa-check"></i><b>9.3.1</b> Multiple testing in real life: p-Hacking and fishing expeditions</a></li>
<li class="chapter" data-level="9.3.2" data-path="big-data-stat.html"><a href="big-data-stat.html#the-land-of-counterfeit-fake-coins"><i class="fa fa-check"></i><b>9.3.2</b> The Land of Counterfeit (fake) coins</a></li>
<li class="chapter" data-level="9.3.3" data-path="big-data-stat.html"><a href="big-data-stat.html#simulation"><i class="fa fa-check"></i><b>9.3.3</b> Simulation</a></li>
<li class="chapter" data-level="9.3.4" data-path="big-data-stat.html"><a href="big-data-stat.html#nominal-p-values"><i class="fa fa-check"></i><b>9.3.4</b> Nominal p-values</a></li>
<li class="chapter" data-level="9.3.5" data-path="big-data-stat.html"><a href="big-data-stat.html#family-wise-error-rate"><i class="fa fa-check"></i><b>9.3.5</b> Family-wise error rate</a></li>
<li class="chapter" data-level="9.3.6" data-path="big-data-stat.html"><a href="big-data-stat.html#false-discovery-rate"><i class="fa fa-check"></i><b>9.3.6</b> False Discovery Rate</a></li>
<li class="chapter" data-level="9.3.7" data-path="big-data-stat.html"><a href="big-data-stat.html#overview-figure"><i class="fa fa-check"></i><b>9.3.7</b> Overview figure</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="big-data-stat.html"><a href="big-data-stat.html#conclusions"><i class="fa fa-check"></i><b>9.4</b> Conclusions</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="big-data-stat.html"><a href="big-data-stat.html#to-remember"><i class="fa fa-check"></i><b>9.4.1</b> To remember</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="big-data-stat.html"><a href="big-data-stat.html#references"><i class="fa fa-check"></i><b>9.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html"><i class="fa fa-check"></i><b>10</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#motivation-and-overview"><i class="fa fa-check"></i><b>10.1</b> Motivation and overview</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#testing-conditional-dependence"><i class="fa fa-check"></i><b>10.1.1</b> Testing conditional dependence</a></li>
<li class="chapter" data-level="10.1.2" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#linear-regression"><i class="fa fa-check"></i><b>10.1.2</b> Linear regression</a></li>
<li class="chapter" data-level="10.1.3" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#limitations"><i class="fa fa-check"></i><b>10.1.3</b> Limitations</a></li>
<li class="chapter" data-level="10.1.4" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#applications"><i class="fa fa-check"></i><b>10.1.4</b> Applications</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#univariate-regression"><i class="fa fa-check"></i><b>10.2</b> Univariate regression</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#galtons-height-dataset"><i class="fa fa-check"></i><b>10.2.1</b> Galton’s height dataset</a></li>
<li class="chapter" data-level="10.2.2" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#ML-LSE"><i class="fa fa-check"></i><b>10.2.2</b> Maximum likelihood and least squares estimates</a></li>
<li class="chapter" data-level="10.2.3" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#interpretation-of-the-fitted-coefficients"><i class="fa fa-check"></i><b>10.2.3</b> Interpretation of the fitted coefficients</a></li>
<li class="chapter" data-level="10.2.4" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#predicted-values-are-random-variables"><i class="fa fa-check"></i><b>10.2.4</b> Predicted values are random variables</a></li>
<li class="chapter" data-level="10.2.5" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#explained-variance"><i class="fa fa-check"></i><b>10.2.5</b> Explained variance</a></li>
<li class="chapter" data-level="10.2.6" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#testing-the-relationship-between-y-and-x"><i class="fa fa-check"></i><b>10.2.6</b> Testing the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span></a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#multivariate-regression"><i class="fa fa-check"></i><b>10.3</b> Multivariate regression</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#a-multivariate-example-the-baseball-dataset"><i class="fa fa-check"></i><b>10.3.1</b> A multivariate example: The baseball dataset</a></li>
<li class="chapter" data-level="10.3.2" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#fitting-multivariate-regression"><i class="fa fa-check"></i><b>10.3.2</b> Fitting multivariate regression</a></li>
<li class="chapter" data-level="10.3.3" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#testing-sets-of-parameters"><i class="fa fa-check"></i><b>10.3.3</b> Testing sets of parameters</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#lin-reg-diagnostic"><i class="fa fa-check"></i><b>10.4</b> Diagnostic plots</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#assessing-non-linearity-with-residual-plot"><i class="fa fa-check"></i><b>10.4.1</b> Assessing non-linearity with residual plot</a></li>
<li class="chapter" data-level="10.4.2" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#when-error-variance-is-not-constant-heteroscedascity"><i class="fa fa-check"></i><b>10.4.2</b> When error variance is not constant: Heteroscedascity</a></li>
<li class="chapter" data-level="10.4.3" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#gaussianity-q-q-plot-of-the-residuals"><i class="fa fa-check"></i><b>10.4.3</b> Gaussianity: Q-Q-plot of the residuals</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="chap-lin-reg.html"><a href="chap-lin-reg.html#conclusions-1"><i class="fa fa-check"></i><b>10.5</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chap-log-reg.html"><a href="chap-log-reg.html"><i class="fa fa-check"></i><b>11</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="chap-log-reg.html"><a href="chap-log-reg.html#a-univariate-example-predicting-sex-given-the-height"><i class="fa fa-check"></i><b>11.1</b> A univariate example: predicting sex given the height</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="chap-log-reg.html"><a href="chap-log-reg.html#from-linear-regression-to-logistic-regression"><i class="fa fa-check"></i><b>11.1.1</b> From linear regression to logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="chap-log-reg.html"><a href="chap-log-reg.html#ML-CE"><i class="fa fa-check"></i><b>11.2</b> Maximum likelihood estimates and the cross-entropy criterion</a></li>
<li class="chapter" data-level="11.3" data-path="chap-log-reg.html"><a href="chap-log-reg.html#logistic-regression-as-a-generalized-linear-model"><i class="fa fa-check"></i><b>11.3</b> Logistic regression as a generalized linear model</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="chap-log-reg.html"><a href="chap-log-reg.html#logistic-regression-with-r"><i class="fa fa-check"></i><b>11.3.1</b> Logistic regression with R</a></li>
<li class="chapter" data-level="11.3.2" data-path="chap-log-reg.html"><a href="chap-log-reg.html#overview-plot-of-the-univariate-example"><i class="fa fa-check"></i><b>11.3.2</b> Overview plot of the univariate example</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chap-log-reg.html"><a href="chap-log-reg.html#interpreting-a-logistic-regression-fit"><i class="fa fa-check"></i><b>11.4</b> Interpreting a logistic regression fit</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="chap-log-reg.html"><a href="chap-log-reg.html#predicted-odds"><i class="fa fa-check"></i><b>11.4.1</b> Predicted odds</a></li>
<li class="chapter" data-level="11.4.2" data-path="chap-log-reg.html"><a href="chap-log-reg.html#coefficients-of-the-logistic-regression"><i class="fa fa-check"></i><b>11.4.2</b> Coefficients of the logistic regression</a></li>
<li class="chapter" data-level="11.4.3" data-path="chap-log-reg.html"><a href="chap-log-reg.html#effects-on-probabilities"><i class="fa fa-check"></i><b>11.4.3</b> Effects on probabilities</a></li>
<li class="chapter" data-level="11.4.4" data-path="chap-log-reg.html"><a href="chap-log-reg.html#class-imbalance"><i class="fa fa-check"></i><b>11.4.4</b> Class imbalance</a></li>
<li class="chapter" data-level="11.4.5" data-path="chap-log-reg.html"><a href="chap-log-reg.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>11.4.5</b> Multiple Logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="chap-log-reg.html"><a href="chap-log-reg.html#assessing-the-performance-of-a-classifier"><i class="fa fa-check"></i><b>11.5</b> Assessing the performance of a classifier</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="chap-log-reg.html"><a href="chap-log-reg.html#classification-with-logistic-regression"><i class="fa fa-check"></i><b>11.5.1</b> Classification with logistic regression</a></li>
<li class="chapter" data-level="11.5.2" data-path="chap-log-reg.html"><a href="chap-log-reg.html#confusion-matrix"><i class="fa fa-check"></i><b>11.5.2</b> Confusion Matrix</a></li>
<li class="chapter" data-level="11.5.3" data-path="chap-log-reg.html"><a href="chap-log-reg.html#classification-performance-metrics"><i class="fa fa-check"></i><b>11.5.3</b> Classification performance metrics</a></li>
<li class="chapter" data-level="11.5.4" data-path="chap-log-reg.html"><a href="chap-log-reg.html#choosing-a-classification-cutoff"><i class="fa fa-check"></i><b>11.5.4</b> Choosing a classification cutoff</a></li>
<li class="chapter" data-level="11.5.5" data-path="chap-log-reg.html"><a href="chap-log-reg.html#roc-curve"><i class="fa fa-check"></i><b>11.5.5</b> ROC curve</a></li>
<li class="chapter" data-level="11.5.6" data-path="chap-log-reg.html"><a href="chap-log-reg.html#precision-recall-curve"><i class="fa fa-check"></i><b>11.5.6</b> Precision Recall curve</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="chap-log-reg.html"><a href="chap-log-reg.html#conclusions-2"><i class="fa fa-check"></i><b>11.6</b> Conclusions</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="chap-log-reg.html"><a href="chap-log-reg.html#to-remember-1"><i class="fa fa-check"></i><b>11.6.1</b> To remember</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>12</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="supervised-learning.html"><a href="supervised-learning.html#introduction-3"><i class="fa fa-check"></i><b>12.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="supervised-learning.html"><a href="supervised-learning.html#motivation-2"><i class="fa fa-check"></i><b>12.1.1</b> Motivation</a></li>
<li class="chapter" data-level="12.1.2" data-path="supervised-learning.html"><a href="supervised-learning.html#supervised-learning-vs.-unsupervised-learning"><i class="fa fa-check"></i><b>12.1.2</b> Supervised learning vs. unsupervised learning</a></li>
<li class="chapter" data-level="12.1.3" data-path="supervised-learning.html"><a href="supervised-learning.html#notation"><i class="fa fa-check"></i><b>12.1.3</b> Notation</a></li>
<li class="chapter" data-level="12.1.4" data-path="supervised-learning.html"><a href="supervised-learning.html#basic-approach-in-supervised-machine-learning"><i class="fa fa-check"></i><b>12.1.4</b> Basic approach in supervised machine learning</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="supervised-learning.html"><a href="supervised-learning.html#over--and-under-fitting"><i class="fa fa-check"></i><b>12.2</b> Over- and Under-fitting</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="supervised-learning.html"><a href="supervised-learning.html#example-polynomial-curve-fitting"><i class="fa fa-check"></i><b>12.2.1</b> Example: polynomial curve fitting</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="supervised-learning.html"><a href="supervised-learning.html#splitting-the-dataset-for-performance-assessment"><i class="fa fa-check"></i><b>12.3</b> Splitting the dataset for performance assessment</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="supervised-learning.html"><a href="supervised-learning.html#over-fitting-to-the-training-dataset"><i class="fa fa-check"></i><b>12.3.1</b> Over-fitting to the training dataset</a></li>
<li class="chapter" data-level="12.3.2" data-path="supervised-learning.html"><a href="supervised-learning.html#cross-validation"><i class="fa fa-check"></i><b>12.3.2</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="supervised-learning.html"><a href="supervised-learning.html#random-forests-as-alternative-models"><i class="fa fa-check"></i><b>12.4</b> Random Forests as alternative models</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="supervised-learning.html"><a href="supervised-learning.html#the-basics-of-decision-trees"><i class="fa fa-check"></i><b>12.4.1</b> The basics of decision trees</a></li>
<li class="chapter" data-level="12.4.2" data-path="supervised-learning.html"><a href="supervised-learning.html#random-forests-for-classification-and-regression-tasks"><i class="fa fa-check"></i><b>12.4.2</b> Random Forests for classification and regression tasks</a></li>
<li class="chapter" data-level="12.4.3" data-path="supervised-learning.html"><a href="supervised-learning.html#random-forests-in-r"><i class="fa fa-check"></i><b>12.4.3</b> Random Forests in R</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="supervised-learning.html"><a href="supervised-learning.html#conclusion-2"><i class="fa fa-check"></i><b>12.5</b> Conclusion</a></li>
<li class="chapter" data-level="12.6" data-path="supervised-learning.html"><a href="supervised-learning.html#resources-4"><i class="fa fa-check"></i><b>12.6</b> Resources</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="importing-data.html"><a href="importing-data.html"><i class="fa fa-check"></i><b>A</b> Importing data</a>
<ul>
<li class="chapter" data-level="A.1" data-path="importing-data.html"><a href="importing-data.html#paths-and-the-working-directory"><i class="fa fa-check"></i><b>A.1</b> Paths and the working directory</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="importing-data.html"><a href="importing-data.html#the-filesystem"><i class="fa fa-check"></i><b>A.1.1</b> The filesystem</a></li>
<li class="chapter" data-level="A.1.2" data-path="importing-data.html"><a href="importing-data.html#relative-and-full-paths"><i class="fa fa-check"></i><b>A.1.2</b> Relative and full paths</a></li>
<li class="chapter" data-level="A.1.3" data-path="importing-data.html"><a href="importing-data.html#the-working-directory"><i class="fa fa-check"></i><b>A.1.3</b> The working directory</a></li>
<li class="chapter" data-level="A.1.4" data-path="importing-data.html"><a href="importing-data.html#generating-path-names"><i class="fa fa-check"></i><b>A.1.4</b> Generating path names</a></li>
<li class="chapter" data-level="A.1.5" data-path="importing-data.html"><a href="importing-data.html#copying-files-using-paths"><i class="fa fa-check"></i><b>A.1.5</b> Copying files using paths</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="importing-data.html"><a href="importing-data.html#the-readr-and-readxl-packages"><i class="fa fa-check"></i><b>A.2</b> The readr and readxl packages</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="importing-data.html"><a href="importing-data.html#readr"><i class="fa fa-check"></i><b>A.2.1</b> readr</a></li>
<li class="chapter" data-level="A.2.2" data-path="importing-data.html"><a href="importing-data.html#readxl"><i class="fa fa-check"></i><b>A.2.2</b> readxl</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="importing-data.html"><a href="importing-data.html#exercises"><i class="fa fa-check"></i><b>A.3</b> Exercises</a></li>
<li class="chapter" data-level="A.4" data-path="importing-data.html"><a href="importing-data.html#downloading-files"><i class="fa fa-check"></i><b>A.4</b> Downloading files</a></li>
<li class="chapter" data-level="A.5" data-path="importing-data.html"><a href="importing-data.html#r-base-importing-functions"><i class="fa fa-check"></i><b>A.5</b> R-base importing functions</a>
<ul>
<li><a href="importing-data.html#scan"><code>scan</code></a></li>
</ul></li>
<li class="chapter" data-level="A.6" data-path="importing-data.html"><a href="importing-data.html#text-versus-binary-files"><i class="fa fa-check"></i><b>A.6</b> Text versus binary files</a></li>
<li class="chapter" data-level="A.7" data-path="importing-data.html"><a href="importing-data.html#unicode-versus-ascii"><i class="fa fa-check"></i><b>A.7</b> Unicode versus ASCII</a></li>
<li class="chapter" data-level="A.8" data-path="importing-data.html"><a href="importing-data.html#organizing-data-with-spreadsheets"><i class="fa fa-check"></i><b>A.8</b> Organizing data with spreadsheets</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendix-r-programming.html"><a href="appendix-r-programming.html"><i class="fa fa-check"></i><b>B</b> R programming</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendix-r-programming.html"><a href="appendix-r-programming.html#conditionals"><i class="fa fa-check"></i><b>B.1</b> Conditional expressions</a></li>
<li class="chapter" data-level="B.2" data-path="appendix-r-programming.html"><a href="appendix-r-programming.html#defining-functions"><i class="fa fa-check"></i><b>B.2</b> Defining functions</a></li>
<li class="chapter" data-level="B.3" data-path="appendix-r-programming.html"><a href="appendix-r-programming.html#namespaces"><i class="fa fa-check"></i><b>B.3</b> Namespaces</a></li>
<li class="chapter" data-level="B.4" data-path="appendix-r-programming.html"><a href="appendix-r-programming.html#for-loops"><i class="fa fa-check"></i><b>B.4</b> For-loops</a></li>
<li class="chapter" data-level="B.5" data-path="appendix-r-programming.html"><a href="appendix-r-programming.html#vectorization"><i class="fa fa-check"></i><b>B.5</b> Vectorization and functionals</a></li>
<li class="chapter" data-level="B.6" data-path="appendix-r-programming.html"><a href="appendix-r-programming.html#r-markdown"><i class="fa fa-check"></i><b>B.6</b> R Markdown</a></li>
<li class="chapter" data-level="B.7" data-path="appendix-r-programming.html"><a href="appendix-r-programming.html#resources-5"><i class="fa fa-check"></i><b>B.7</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="additonal-plotting-tools.html"><a href="additonal-plotting-tools.html"><i class="fa fa-check"></i><b>C</b> Additonal plotting tools</a>
<ul>
<li class="chapter" data-level="C.1" data-path="additonal-plotting-tools.html"><a href="additonal-plotting-tools.html#plotting-themes"><i class="fa fa-check"></i><b>C.1</b> Plotting themes</a></li>
<li class="chapter" data-level="C.2" data-path="additonal-plotting-tools.html"><a href="additonal-plotting-tools.html#axes"><i class="fa fa-check"></i><b>C.2</b> Axes</a>
<ul>
<li class="chapter" data-level="C.2.1" data-path="additonal-plotting-tools.html"><a href="additonal-plotting-tools.html#axis-elements"><i class="fa fa-check"></i><b>C.2.1</b> Axis elements</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="additonal-plotting-tools.html"><a href="additonal-plotting-tools.html#plot-title"><i class="fa fa-check"></i><b>C.3</b> Plot title</a></li>
<li class="chapter" data-level="C.4" data-path="additonal-plotting-tools.html"><a href="additonal-plotting-tools.html#legend"><i class="fa fa-check"></i><b>C.4</b> Legend</a></li>
<li class="chapter" data-level="C.5" data-path="additonal-plotting-tools.html"><a href="additonal-plotting-tools.html#interactive-plots"><i class="fa fa-check"></i><b>C.5</b> Interactive plots</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="appendix-probabilities.html"><a href="appendix-probabilities.html"><i class="fa fa-check"></i><b>D</b> Probabilities</a>
<ul>
<li class="chapter" data-level="D.1" data-path="appendix-probabilities.html"><a href="appendix-probabilities.html#probability-conditional-probability-and-dependence"><i class="fa fa-check"></i><b>D.1</b> Probability, conditional probability, and dependence</a></li>
<li class="chapter" data-level="D.2" data-path="appendix-probabilities.html"><a href="appendix-probabilities.html#expected-value-variance-and-covariance"><i class="fa fa-check"></i><b>D.2</b> Expected value, variance, and covariance</a></li>
<li class="chapter" data-level="D.3" data-path="appendix-probabilities.html"><a href="appendix-probabilities.html#sample-estimates"><i class="fa fa-check"></i><b>D.3</b> Sample estimates</a></li>
<li class="chapter" data-level="D.4" data-path="appendix-probabilities.html"><a href="appendix-probabilities.html#appendix-lin-reg"><i class="fa fa-check"></i><b>D.4</b> Linear regression</a></li>
<li class="chapter" data-level="D.5" data-path="appendix-probabilities.html"><a href="appendix-probabilities.html#resources-6"><i class="fa fa-check"></i><b>D.5</b> Resources</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="./">Julien Gagneur, TUM</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis and Visualization in R (IN2339)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="resampling-stat" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Resampling-based Statistical Assessment</h1>
<!-- We have so far based all our analyses on visualizations. Algorithms have been employed only for helping visualization of high-dimensional datasets.  -->
<!-- As described in the last Chapter, one of the main goal of data analysis is to identify interesting associations between variables.  -->
<!--
Suppose we have found a trend in a dataset, which leads us to think some property holds true. For example, while analyzing data on flight delays, we might discover that American Airlines has the worst delays:


```r
flightsLAX <- fread('extdata/flights/flightsLAX.csv')
ggplot(flightsLAX[ARRIVAL_DELAY>30],aes(AIRLINE,ARRIVAL_DELAY))+geom_violin()
```

<img src="dataviz_book_files/figure-html/lecture-02-287-1.png" width="1000px" />

So, we might conclude that if we have the choice, we should not fly with American, correct?

Now, consider: another scenario. 
-->
<p>Suppose a friend says she can correctly predict the winning team in any football game, due to her deep knowledge of the sport. To test this, we ask for her predictions for two Champions League games. She turns out to be right both times. On a first glance, this seems very impressive: she has a <span class="math inline">\(100\%\)</span> success rate! Should we hence bet a lot of money on her next prediction? What if she is just guessing and got lucky?</p>
<p>Someone who just flips a coin to decide the winner has a <span class="math inline">\(25\%\)</span> chance to get lucky and guess two games correctly. Accordingly, betting all our life savings that she will be right again next game may not be a very good idea. Hence, the danger is to conclude something based on a limited amount of data. Apparent trends can arise purely by chance, and if we are not careful this can lead us into making the wrong conclusions. Now, what if the friend had correctly predicted the outcome in 4 out of 5 games? What about 237 out of 286 games? When should we start taking her claim seriously?</p>
<!--
Both of these examples have one thing in common: we are trying to conclude something based on a limited amount of data. The danger in doing this is that we can be "fooled by randomness". Because our data is noisy, apparent trends can arise purely by chance, and if we are not careful this can lead us into making the wrong conclusions.

Let us look at our examples again:

For the flights example, it is instructive to look at the median delays:

```r
ggplot(flightsLAX[ARRIVAL_DELAY>30],aes(AIRLINE,ARRIVAL_DELAY)) + geom_boxplot() +
  scale_y_log10()
```

<img src="dataviz_book_files/figure-html/lecture-02-288-1.png" width="1000px" />
We see that in terms of the median delay, the airlines all look very similar. We see furthermore that the trend of extreme delays from AA seems to be driven by a small number of flights. Given this, we maybe should be skeptical of making strong conclusions.

For the football example, we can be equally skeptical. 
-->
<p>This chapter introduces concepts and methods to answer these types of questions. We cover the concept of hypothesis testing and of statistical significance, which is another way of saying that a trend is unlikely to have arisen purely by chance. We also introduce the concept of confidence interval which models our uncertainty when estimating parameters such as the mean of a variable. To this end, we provide two largely applicable computational methods: permutation testing and case resampling. These methods are based on resampling the data at hand, thereby making little modeling assumptions.</p>
<div id="yeast-dataset" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> The yeast dataset</h2>
<div id="the-experiment" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> The experiment</h3>
<p>This section introduces a dataset that we will use throughout this chapter, and occasionally in the following chapters.</p>
<p>Yeast is a good old friend of humans. Thanks to yeast, we can make bread, wine, and (not the least for TUM and Munich) beer. Yeast is also very much studied by biologists. The yeast strain that is commonly used in research labs grows poorly on maltose compared to wild yeast strains. Hard to brew malt beer with the lab strain… One may wonder whether the lab strain has acquired a genetic mutation causing this poor fitness in maltose media. If so, on which chromosome, near which gene?</p>
<p>Our dataset <span class="citation">(<a href="#ref-gagneur2013" role="doc-biblioref">Gagneur et al. 2013</a>)</span> allows addressing these questions (and further yeast genetic questions). The lab strain was crossed with a wild isolate growing well on maltose. Overall, 184 offsprings, also called segregants, were obtained. During a cross, parental chromosomes are recombined at discrete random locations in a process called cross-over.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> Consequently, the chromosomes of the segregants consist of alternated segments inherited from either parent. Yeast has 16 chromosomes. Figure <a href="resampling-stat.html#fig:yeast-cross">7.1</a> illustrates this crossing process for one chromosome.</p>
<div class="figure"><span style="display:block;" id="fig:yeast-cross"></span>
<img src="assets/img/lec09-stat-testing/lec09_yeast_cross.png" alt="Cross of the lab strain and wild isolate. Meiotic recombination implies that chromosomes of the offsprings consist of alternated segments inherited from either parent." width="600px" />
<p class="caption">
Figure 7.1: Cross of the lab strain and wild isolate. Meiotic recombination implies that chromosomes of the offsprings consist of alternated segments inherited from either parent.
</p>
</div>
<p>This shuffling of the genetic information is helpful to identify on which chromosomal location(s) genetic variations responsible for the growth rate difference could reside.</p>
</div>
<div id="genotype" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Genotype</h3>
<p>The <code>genotype</code> table reports the genotype of each the 184 yeast strains at 1,000 genomic locations called genetic markers. At each marker, the genotype values are either “Lab strain” or “Wild isolate” (Figure <a href="resampling-stat.html#fig:genotype-matrix">7.2</a>).</p>
<div class="figure"><span style="display:block;" id="fig:genotype-matrix"></span>
<img src="assets/img/lec09-stat-testing/lec09_genotype.png" alt="Sketch of the genotype of segregants (rows) across the 16 chromosomes. The genotypes are provided at 1,000 genomic positions (called markers, vertical line)." width="800px" />
<p class="caption">
Figure 7.2: Sketch of the genotype of segregants (rows) across the 16 chromosomes. The genotypes are provided at 1,000 genomic positions (called markers, vertical line).
</p>
</div>
<p>See below for a section of the data table:</p>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="resampling-stat.html#cb475-1" aria-hidden="true" tabindex="-1"></a>genotype <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;extdata/eqtl/genotype.txt&quot;</span>)</span>
<span id="cb475-2"><a href="resampling-stat.html#cb475-2" aria-hidden="true" tabindex="-1"></a>genotype <span class="ot">&lt;-</span> genotype <span class="sc">%&gt;%</span> </span>
<span id="cb475-3"><a href="resampling-stat.html#cb475-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">melt</span>(<span class="at">id.vars =</span> <span class="st">&#39;strain&#39;</span>, <span class="at">variable.name =</span> <span class="st">&#39;marker&#39;</span>, <span class="at">value.name =</span> <span class="st">&#39;genotype&#39;</span>)</span>
<span id="cb475-4"><a href="resampling-stat.html#cb475-4" aria-hidden="true" tabindex="-1"></a>genotype</span></code></pre></div>
<pre><code>##          strain    marker     genotype
##      1: seg_01B     mrk_1   Lab strain
##      2: seg_01C     mrk_1 Wild isolate
##      3: seg_01D     mrk_1   Lab strain
##      4: seg_02B     mrk_1   Lab strain
##      5: seg_02C     mrk_1 Wild isolate
##     ---                               
## 157996: seg_49A mrk_13314   Lab strain
## 157997: seg_49B mrk_13314 Wild isolate
## 157998: seg_50A mrk_13314   Lab strain
## 157999: seg_50B mrk_13314 Wild isolate
## 158000: seg_50D mrk_13314   Lab strain</code></pre>
<p>If we want to know where the markers are located in the genome, we can consult the <code>marker</code> table. This table reports genomic coordinates of the markers (chromosome, start, and stop):</p>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb477-1"><a href="resampling-stat.html#cb477-1" aria-hidden="true" tabindex="-1"></a>marker <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;extdata/eqtl/marker.txt&quot;</span>)</span>
<span id="cb477-2"><a href="resampling-stat.html#cb477-2" aria-hidden="true" tabindex="-1"></a>marker</span></code></pre></div>
<pre><code>##              id chrom  start    end
##    1:     mrk_1 chr01   1512   2366
##    2:    mrk_14 chr01  29161  29333
##    3:    mrk_27 chr01  38275  38317
##    4:    mrk_40 chr01  47695  47695
##    5:    mrk_54 chr01  56059  56059
##   ---                              
##  996: mrk_13260 chr16 928119 928130
##  997: mrk_13274 chr16 931402 931594
##  998: mrk_13287 chr16 934388 934624
##  999: mrk_13300 chr16 939647 939679
## 1000: mrk_13314 chr16 944640 944667</code></pre>
</div>
<div id="growth-rates" class="section level3" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> Growth rates</h3>
<p>The <code>growth</code> table contains the growth rates expressed in generations per day for each strain in five different growth media. These growth media are YPD (glucose), YPD_BPS (low iron), YPD_Rapa (Rapamycin), YPE (Ethanol), YPMalt (Maltose).</p>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb479-1"><a href="resampling-stat.html#cb479-1" aria-hidden="true" tabindex="-1"></a>growth <span class="ot">&lt;-</span> <span class="fu">fread</span>(<span class="st">&quot;extdata/eqtl/growth.txt&quot;</span>)</span>
<span id="cb479-2"><a href="resampling-stat.html#cb479-2" aria-hidden="true" tabindex="-1"></a>growth <span class="ot">&lt;-</span> growth <span class="sc">%&gt;%</span> <span class="fu">melt</span>(<span class="at">id.vars =</span> <span class="st">&quot;strain&quot;</span>, <span class="at">variable.name =</span> <span class="st">&#39;media&#39;</span>, <span class="at">value.name =</span> <span class="st">&#39;growth_rate&#39;</span>)</span>
<span id="cb479-3"><a href="resampling-stat.html#cb479-3" aria-hidden="true" tabindex="-1"></a>growth</span></code></pre></div>
<pre><code>##       strain  media growth_rate
##   1: seg_01B    YPD   12.603986
##   2: seg_01C    YPD   10.791144
##   3: seg_01D    YPD   12.817268
##   4: seg_02B    YPD   10.299210
##   5: seg_02C    YPD   11.132778
##  ---                           
## 786: seg_49A YPMalt    4.592395
## 787: seg_49B YPMalt    5.702087
## 788: seg_50A YPMalt    4.303382
## 789: seg_50B YPMalt    6.583852
## 790: seg_50D YPMalt    7.421968</code></pre>
</div>
<div id="genotype-growth-rate-association-in-maltose-at-a-specific-marker" class="section level3" number="7.1.4">
<h3><span class="header-section-number">7.1.4</span> Genotype-growth rate association in maltose at a specific marker</h3>
<p>In this Chapter, we focus on a simple, targeted question. We know beforehand that the gene MAL13 is important for maltose metabolism. Could genetic variation between the lab strain and the wild isolate near the gene MAL13 be responsible for the growth difference in maltose?</p>
<p>Marker 5211, which starts at positions 1069229 of chromosome 07, is the closest marker to the gene MAL13. We thus ask whether genotype at marker 5211 associates with growth rate in maltose.<br />
To assess this hypothesis, we first create a data table called <code>dt</code> that contains the relevant data and visualize with a boxplot how growth rates distributes depending on the genotype at marker 5211:</p>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb481-1"><a href="resampling-stat.html#cb481-1" aria-hidden="true" tabindex="-1"></a>mk <span class="ot">&lt;-</span> marker[chrom <span class="sc">==</span> <span class="st">&quot;chr07&quot;</span> <span class="sc">&amp;</span> start <span class="sc">==</span> <span class="dv">1069229</span>, id]</span>
<span id="cb481-2"><a href="resampling-stat.html#cb481-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb481-3"><a href="resampling-stat.html#cb481-3" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">merge</span>(</span>
<span id="cb481-4"><a href="resampling-stat.html#cb481-4" aria-hidden="true" tabindex="-1"></a>  growth[media <span class="sc">==</span> <span class="st">&#39;YPMalt&#39;</span>],</span>
<span id="cb481-5"><a href="resampling-stat.html#cb481-5" aria-hidden="true" tabindex="-1"></a>  genotype[marker <span class="sc">==</span> mk, .(strain, genotype)],</span>
<span id="cb481-6"><a href="resampling-stat.html#cb481-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">by =</span> <span class="st">&#39;strain&#39;</span></span>
<span id="cb481-7"><a href="resampling-stat.html#cb481-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb481-8"><a href="resampling-stat.html#cb481-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb481-9"><a href="resampling-stat.html#cb481-9" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> dt<span class="sc">%&gt;%</span> </span>
<span id="cb481-10"><a href="resampling-stat.html#cb481-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(., <span class="fu">aes</span>(genotype, growth_rate)) <span class="sc">+</span></span>
<span id="cb481-11"><a href="resampling-stat.html#cb481-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb481-12"><a href="resampling-stat.html#cb481-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">paste0</span>(<span class="st">&quot;Genotype at &quot;</span>, mk)) <span class="sc">+</span> </span>
<span id="cb481-13"><a href="resampling-stat.html#cb481-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Growth rate in Maltose [Generations/day]&quot;</span>) <span class="sc">+</span></span>
<span id="cb481-14"><a href="resampling-stat.html#cb481-14" aria-hidden="true" tabindex="-1"></a>  mytheme</span>
<span id="cb481-15"><a href="resampling-stat.html#cb481-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb481-16"><a href="resampling-stat.html#cb481-16" aria-hidden="true" tabindex="-1"></a>p</span></code></pre></div>
<p><img src="dataviz_book_files/figure-html/lecture-02-292-1.png" width="384" /></p>
<div class="sourceCode" id="cb482"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb482-1"><a href="resampling-stat.html#cb482-1" aria-hidden="true" tabindex="-1"></a>dt[genotype <span class="sc">==</span> <span class="st">&#39;Wild isolate&#39;</span>, <span class="fu">median</span>(growth_rate, <span class="at">na.rm=</span>T)] <span class="sc">-</span> </span>
<span id="cb482-2"><a href="resampling-stat.html#cb482-2" aria-hidden="true" tabindex="-1"></a>    dt[genotype <span class="sc">==</span> <span class="st">&#39;Lab strain&#39;</span>, <span class="fu">median</span>(growth_rate, <span class="at">na.rm=</span>T)]</span></code></pre></div>
<pre><code>## [1] 2.172018</code></pre>
<p>We see that genotype at that marker indeed associates with a strong difference in growth rates in the Maltose media, with a difference between the medians of 2.17 generations per day.</p>
<p>But, as we already discussed in the motivating section, we need to be careful before making any conclusions. Maybe the pattern we see is an artifact of random variation and would disappear if we had more data. In the following we approach this issue with two concepts. We first look at statistical hypothesis testing, assessing whether the association could have arisen by chance. Next, we will consider parameter uncertainty, which will provide error bars around our difference of medians estimate.</p>
</div>
</div>
<div id="statistical-hypothesis-testing" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Statistical hypothesis testing</h2>
<p>Statistical hypothesis testing, often just referred to as hypothesis testing, is a method to assess whether an observed trend could have arisen by chance. We first describe intuitively a specific hypothesis testing method called permutation testing, to then describe the general concept.</p>
<div id="permut-test-build-up" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Permutation testing: An intuitive build-up</h3>
<p>We take the proverbial “Devil’s Advocate” standpoint. We consider the possibility that such a large difference of growth rate medians could often arise by chance, would we make arbitrary groups of the same size than those defined by the genotype.</p>
<p>To simulate such random data, we permute the values of the genotype keeping the growth rate values fixed. To permute values of a vector we can use the R function <code>sample()</code> with default parameters as in the example below:</p>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb484-1"><a href="resampling-stat.html#cb484-1" aria-hidden="true" tabindex="-1"></a>LETTERS[<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>]</span></code></pre></div>
<pre><code>## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot;</code></pre>
<div class="sourceCode" id="cb486"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb486-1"><a href="resampling-stat.html#cb486-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(LETTERS[<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>])</span></code></pre></div>
<pre><code>## [1] &quot;B&quot; &quot;H&quot; &quot;D&quot; &quot;G&quot; &quot;A&quot; &quot;E&quot; &quot;F&quot; &quot;C&quot;</code></pre>
<p>We now shuffle the genotype column. To keep the original data safe, we work on <code>dt_permuted</code>, a copy of the table <code>dt</code>.</p>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb488-1"><a href="resampling-stat.html#cb488-1" aria-hidden="true" tabindex="-1"></a>dt_permuted <span class="ot">&lt;-</span> <span class="fu">copy</span>(dt)</span>
<span id="cb488-2"><a href="resampling-stat.html#cb488-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>) <span class="co"># the seed of the random number generator</span></span>
<span id="cb488-3"><a href="resampling-stat.html#cb488-3" aria-hidden="true" tabindex="-1"></a>dt_permuted[ , genotype<span class="sc">:</span><span class="er">=</span><span class="fu">sample</span>(genotype)]</span></code></pre></div>
<p>For this simulated data, the boxplot looks less impressive:</p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb489-1"><a href="resampling-stat.html#cb489-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The %+% operator updates the dataset of a ggplot object</span></span>
<span id="cb489-2"><a href="resampling-stat.html#cb489-2" aria-hidden="true" tabindex="-1"></a><span class="co"># convenient, isn&#39;t it?</span></span>
<span id="cb489-3"><a href="resampling-stat.html#cb489-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">%+%</span> dt_permuted </span>
<span id="cb489-4"><a href="resampling-stat.html#cb489-4" aria-hidden="true" tabindex="-1"></a>p</span></code></pre></div>
<p><img src="dataviz_book_files/figure-html/lecture-02-296-1.png" width="384" /></p>
<p>We can also recompute the difference of medians. To not have repeated code, let us define a function (See Appendix <a href="appendix-r-programming.html#appendix-r-programming">B</a>) that takes a table as input. We check immediately that our function properly returns the original difference of medians when applied to <code>dt</code>.</p>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb490-1"><a href="resampling-stat.html#cb490-1" aria-hidden="true" tabindex="-1"></a>diff_median <span class="ot">&lt;-</span> <span class="cf">function</span>(tab){</span>
<span id="cb490-2"><a href="resampling-stat.html#cb490-2" aria-hidden="true" tabindex="-1"></a>  tab[genotype <span class="sc">==</span> <span class="st">&#39;Wild isolate&#39;</span>, <span class="fu">median</span>(growth_rate, <span class="at">na.rm=</span>T)] <span class="sc">-</span> </span>
<span id="cb490-3"><a href="resampling-stat.html#cb490-3" aria-hidden="true" tabindex="-1"></a>    tab[genotype <span class="sc">==</span> <span class="st">&#39;Lab strain&#39;</span>, <span class="fu">median</span>(growth_rate, <span class="at">na.rm=</span>T)]</span>
<span id="cb490-4"><a href="resampling-stat.html#cb490-4" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb490-5"><a href="resampling-stat.html#cb490-5" aria-hidden="true" tabindex="-1"></a>T_obs <span class="ot">&lt;-</span> <span class="fu">diff_median</span>(dt)</span>
<span id="cb490-6"><a href="resampling-stat.html#cb490-6" aria-hidden="true" tabindex="-1"></a>T_obs</span></code></pre></div>
<pre><code>## [1] 2.172018</code></pre>
<p>The difference of medians in this permuted dataset is now only 0.21 generations per day:</p>
<div class="sourceCode" id="cb492"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb492-1"><a href="resampling-stat.html#cb492-1" aria-hidden="true" tabindex="-1"></a><span class="fu">diff_median</span>(dt_permuted)</span></code></pre></div>
<pre><code>## [1] 0.2135481</code></pre>
<p>This is not fully convincing yet. Maybe our “devil’s advocate” has been unlucky with this one randomization. However, we can easily repeat this operation many times, e.g. 1,000 times. We denote the number of permutations <span class="math inline">\(m\)</span>. We iterate <span class="math inline">\(m\)</span> times using a for loop (See Appendix <a href="appendix-r-programming.html#appendix-r-programming">B</a>). We record the difference of medians of the i-th iteration in a vector called <code>T_permuted</code>.</p>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb494-1"><a href="resampling-stat.html#cb494-1" aria-hidden="true" tabindex="-1"></a><span class="co"># number of permutations</span></span>
<span id="cb494-2"><a href="resampling-stat.html#cb494-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="dv">1000</span> </span>
<span id="cb494-3"><a href="resampling-stat.html#cb494-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb494-4"><a href="resampling-stat.html#cb494-4" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize T_permuted with missing values</span></span>
<span id="cb494-5"><a href="resampling-stat.html#cb494-5" aria-hidden="true" tabindex="-1"></a><span class="co"># (safer than with 0&#39;s)</span></span>
<span id="cb494-6"><a href="resampling-stat.html#cb494-6" aria-hidden="true" tabindex="-1"></a>T_permuted <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, m)</span>
<span id="cb494-7"><a href="resampling-stat.html#cb494-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb494-8"><a href="resampling-stat.html#cb494-8" aria-hidden="true" tabindex="-1"></a><span class="co"># iterate for i=1 to m</span></span>
<span id="cb494-9"><a href="resampling-stat.html#cb494-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>m){</span>
<span id="cb494-10"><a href="resampling-stat.html#cb494-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># permute the genotype column in place </span></span>
<span id="cb494-11"><a href="resampling-stat.html#cb494-11" aria-hidden="true" tabindex="-1"></a>  dt_permuted[ , genotype<span class="sc">:</span><span class="er">=</span><span class="fu">sample</span>(genotype)]</span>
<span id="cb494-12"><a href="resampling-stat.html#cb494-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># store the difference of medians in the i-th entry of T_permuted</span></span>
<span id="cb494-13"><a href="resampling-stat.html#cb494-13" aria-hidden="true" tabindex="-1"></a>  T_permuted[i] <span class="ot">&lt;-</span> <span class="fu">diff_median</span>(dt_permuted)</span>
<span id="cb494-14"><a href="resampling-stat.html#cb494-14" aria-hidden="true" tabindex="-1"></a>} </span></code></pre></div>
<p>Let us look at how these values distribute with a histogram and mark our original observation with a vertical line:</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb495-1"><a href="resampling-stat.html#cb495-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>( <span class="fu">data.table</span>(T_permuted), <span class="fu">aes</span>(<span class="at">x =</span> T_permuted) ) <span class="sc">+</span> </span>
<span id="cb495-2"><a href="resampling-stat.html#cb495-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>() <span class="sc">+</span> </span>
<span id="cb495-3"><a href="resampling-stat.html#cb495-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>( <span class="fu">aes</span>(<span class="at">xintercept=</span>T_obs, <span class="at">color =</span> <span class="st">&quot;T_obs&quot;</span>) )</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with
## `binwidth`.</code></pre>
<p><img src="dataviz_book_files/figure-html/lecture-02-300-1.png" width="480" /></p>
<p>The observed difference of medians stands far out from the distribution of the permuted data. We never observed a difference equal or larger than the original one among 1,000 permutations. We can conclude it is unlikely that such a large difference could have arisen by chance.</p>
<p>This empirical approach is quite intuitive. Let us now formalize it and precisely specify the underlying assumptions in order to understand when and how we can apply it.</p>
</div>
<div id="concepts-of-statistical-hypothesis-testing" class="section level3" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Concepts of Statistical Hypothesis Testing</h3>
<p>We just implemented one type of Hypothesis test. Figure <a href="resampling-stat.html#fig:hypothesis-test-overview">7.3</a> provides an overview of Hypothesis testing.</p>
<div class="figure"><span style="display:block;" id="fig:hypothesis-test-overview"></span>
<img src="assets/img/lec09-stat-testing/lec10_Stat-testing-overview.png" alt="We assume an underlying random process (i.e. 'Nature'). We collected data which is a particular realization of this random process, and from this data we computed a test statistic. In the bottom row, we now play the role of the Devil's Advocate and assume that the underlying random process conforms to the null hypothesis. Based on this assumption, diffrent realization datasets could arise as different realizations of the random process, for which the test statistics would get different values. Then we compute how likely it is to see the test statistics as, or more, extreme as the ones we got from our actual data. We use this probability to reject or not the null hypothesis." width="800px" />
<p class="caption">
Figure 7.3: We assume an underlying random process (i.e. ‘Nature’). We collected data which is a particular realization of this random process, and from this data we computed a test statistic. In the bottom row, we now play the role of the Devil’s Advocate and assume that the underlying random process conforms to the null hypothesis. Based on this assumption, diffrent realization datasets could arise as different realizations of the random process, for which the test statistics would get different values. Then we compute how likely it is to see the test statistics as, or more, extreme as the ones we got from our actual data. We use this probability to reject or not the null hypothesis.
</p>
</div>
<div id="test-statistic" class="section level4" number="7.2.2.1">
<h4><span class="header-section-number">7.2.2.1</span> Test statistic</h4>
<p>To develop our test, we first need to define a <strong>test statistic</strong> (Figure <a href="resampling-stat.html#fig:hypothesis-test-overview">7.3</a>). This is a single number that summarizes the data and captures the trend. The more extreme the test statistic, the stronger the trend.</p>
<p>The test statistic is often denoted <span class="math inline">\(T\)</span>.</p>
<p>Here we have considered the difference of the medians:<br />
<span class="math display">\[ T = \operatorname{median}_{i \in \text{Wild}} (y_i) - \operatorname{median}_{i \in \text{Lab}} (y_i)\]</span></p>
<p>We could equally consider the difference of the means, or the difference of the means divided by the within-group standard deviation, etc. Some statistics are more useful than others, because one can work analytically with them (see next chapter) or because they are more sensitive. Clearly, if we had considered as test statistics the difference between just two random values of each group rather than the difference of medians, discriminating the observed data from the permuted ones would have been more difficult.</p>
</div>
<div id="the-null-hypothesis" class="section level4" number="7.2.2.2">
<h4><span class="header-section-number">7.2.2.2</span> The Null Hypothesis</h4>
<p>Our test statistic is calculated from a limited number of observations. In our data we see a large difference in median growth rates, but maybe if we had much more data, this difference would disappear, or even change sign. To assess this, we need a negative control. We get such a negative control by setting a <strong>null hypothesis</strong> <span class="math inline">\(H_0\)</span>, i.e by assuming that the trend we observe is <em>not</em> real and arose purely by chance (Figure <a href="resampling-stat.html#fig:hypothesis-test-overview">7.3</a>).</p>
<p>The null hypothesis can be compared to the proverbial “Devil’s Advocate.” To test whether a trend is real, we take the skeptical position and assume it is not. It is the same thing we also did in the football example, when we assumed that the friend was just guessing the outcome of the games.</p>
<p>The exact null hypothesis depends on the problem. In our example, the null hypothesis was statistical independence of genotype and growth rate. It can also be that a mean is 0, a Pearson correlation is 0, etc.</p>
</div>
<div id="the-p-value" class="section level4" number="7.2.2.3">
<h4><span class="header-section-number">7.2.2.3</span> The P-value</h4>
<p>Under the null hypothesis <span class="math inline">\(H_0\)</span>, the test statistic <span class="math inline">\(T\)</span> follows a certain distribution <span class="math inline">\(p(T|H_0)\)</span>. The <span class="math inline">\(P\)</span>-value is the probability of obtaining a test statistic the same as or more extreme than the one we actually observed, under the assumption that the null hypothesis is true (See Figure <a href="resampling-stat.html#fig:hypothesis-test-overview">7.3</a>).</p>
<p>The formal definition of the <span class="math inline">\(P\)</span>-value depends on whether we take “more extreme” to mean greater, less, or either way:</p>
<ul>
<li>For right-tail events: <span class="math inline">\(P = p(T \geq T_\text{obs}| H_0)\)</span></li>
<li>For left-tail events: <span class="math inline">\(P = p(T \leq T_\text{obs}| H_0)\)</span></li>
<li>For double tail events: <span class="math inline">\(P = 2\min \{p(T \leq T_\text{obs}| H_0), p(T \geq T_\text{obs}| H_0) \}\)</span></li>
</ul>
<p>The null hypothesis is said to be <strong>rejected</strong> for sufficiently small <span class="math inline">\(P\)</span>-values. In this case we say the result is <strong>statistically significant</strong>. It is common practice in the scientific literature to set a significance level of <span class="math inline">\(\alpha=0.05\)</span> and rejecting the null hypothesis if <span class="math inline">\(P&lt;\alpha\)</span>.</p>
<p>We can explore this definition visually. Assume <span class="math inline">\(p(T|H_0)\)</span>, the distribution of the test statistic under the null hypothesis, looks like this:</p>
<p><img src="dataviz_book_files/figure-html/lecture-02-301-1.png" width="384" /></p>
<p>Now assume the test statistic we observe is <span class="math inline">\(T_\text{obs}=15\)</span>. Then the one-sided <span class="math inline">\(P\)</span>-value is given by the shaded area which corresponds to <span class="math inline">\(p(T \geq T_\text{obs}| H_0)\)</span>:</p>
<p><img src="dataviz_book_files/figure-html/lecture-02-302-1.png" width="384" /></p>
<p>For the two-tailed test, we are not expecting the test statistic to be on the upper or the lower side a priori. We therefore consider where it turned out to be (upper or lower) and double the probability. Graphically, we are summing up the area under the curve on the tail of the observed test statistic (upper or lower) with the equi-probable one of the other tail.</p>
<p><img src="dataviz_book_files/figure-html/lecture-02-303-1.png" width="384" /></p>
<p>This also explains the rather complicated formulation for the two-sided <span class="math inline">\(P\)</span>-value, which we recall is:</p>
<p><span class="math inline">\(P = 2\min \{p(T \leq T_\text{obs}| H_0), p(T \geq T_\text{obs}| H_0) \}\)</span></p>
<p>The <span class="math inline">\(\min\)</span> in this formula is to select the correct tail. If our observed test-statistic is more towards the right tail, as in the above picture, then <span class="math inline">\(p(T \geq T_\text{obs}| H_0)\)</span> will be smaller than <span class="math inline">\(p(T \leq T_\text{obs}| H_0)\)</span>, so the minimum will correctly select the right tail. Then we double this probability, to account for the possibility of observing equally extreme events on the other tail.</p>
<p><strong>When to apply one-sided or two-sided tests?</strong></p>
<p>Say we have as null hypothesis that the true growth rate difference is zero. There are two ways this can be violated: (1) if the true growth rate difference is &gt; 0 or (2) if the true growth difference is &lt; 0. In a one-tailed test, we only account for one of these possibilities. We test <span class="math inline">\(H_0\)</span>: true difference is zero versus <span class="math inline">\(H_1\)</span> (alternative): true difference is &gt; 0, in the first case.
In a two-tailed test, we allow both options. We test <span class="math inline">\(H_0\)</span>: true difference is zero vs. <span class="math inline">\(H_1\)</span> (alternative): true difference is not zero, and we do not care if it ends up being smaller or larger.
In most scenarios the two-tailed test will be most appropriate, as generally there is no reason to privilege effects in one direction over another direction.
A one-tailed test will only make sense if you have very good reason (before looking at the data!) that only the effect in one direction is important.</p>
</div>
<div id="some-intuition-on-hypothesis-testing-and-the-p-value" class="section level4" number="7.2.2.4">
<h4><span class="header-section-number">7.2.2.4</span> Some intuition on Hypothesis Testing and the P-value</h4>
<p>To get some intuition on how to interpret the <span class="math inline">\(P\)</span>-value and this idea of rejecting the null hypothesis, think about a legal trial. Suppose a murder has been committed, and a man has been accused of being the murderer. Under German law he is considered innocent until proven guilty. So, our null hypothesis is that the man is innocent. But we also collect some evidence. For example, we discover that the murder weapon had his finger prints on it, that a witness saw him near the crime scene and that he bought chemicals used to dispose of corpses one day before the crime. None of these facts constitute hard proof that he did commit the crime, but assuming he was innocent, it would require a lot of unlikely coincidences. This corresponds to a scenario where the <span class="math inline">\(P\)</span>-value is low. Thus, we reject the null hypothesis of innocence and convict him.</p>
<p>Conversely, imagine another trial, where the only evidence we have is that an old lady, who sees rather badly, thinks she <em>maybe</em> saw the accused near the crime scene. This corresponds to a scenario where the <span class="math inline">\(P\)</span>-value is high. The accused could be guilty, but it also does not seem implausible that he is innocent and the old lady is just mistaking him for someone else. If we start convicting people based on such flimsy evidence, the jail would quickly be full of innocent people. So we do not reject the null hypothesis of innocence.</p>
</div>
<div id="what-the-p-value-is-not" class="section level4" number="7.2.2.5">
<h4><span class="header-section-number">7.2.2.5</span> What the P-value is not</h4>
<p>The P-value is <em>not</em> the probability of the observed test statistic given that the null hypothesis is true:</p>
<p><span class="math display">\[p(T \geq T_\text{obs}| H_0) \neq p(T=T_\text{obs} | H_0)\]</span></p>
<p>The problem with basing a test on <span class="math inline">\(p(T=T_\text{obs} | H_0)\)</span> is that it is dependent on the space of possibilities. This is most apparent for continuous variables: if <span class="math inline">\(T\)</span> is continuous, then the probability of observing a specific value for the test-statistic, such as <span class="math inline">\(T=0.34257385692956\)</span>, will be zero (recall that, for continuous variables, probabilities are nonzero for intervals only). So <span class="math inline">\(p(T=T_\text{obs} | H_0) = 0\)</span> for all <span class="math inline">\(T\)</span>, thus this would not give useful <span class="math inline">\(P\)</span>-values.</p>
<p>Also, the <span class="math inline">\(P\)</span>-value is <em>not</em> the probability that the null hypothesis is true given the data:</p>
<p><span class="math display">\[p(T \geq T_\text{obs}| H_0) \neq p(H_0 |T=T_\text{obs})\]</span></p>
<p>Consider again the example with the old lady witness. Surely we cannot convict someone of a murder on such weak evidence, thus we do not reject the null hypothesis of innocence. This being said, we also have no evidence to suggest the accused actually is innocent, so we should not conclude that this is definitely the case either! In other words: “absence of evidence is not evidence of absence.”</p>
<p>Related to this, it is important to note the terminology we used above: when the <span class="math inline">\(P\)</span>-value is less than the chosen significance level, we <strong>reject</strong> the null hypothesis. But, in this framework, there is no mechanism to accept the null hypothesis. We can only <em>fail to reject</em> it.</p>
</div>
</div>
<div id="permutation-testing-formally" class="section level3" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Permutation testing, formally</h3>
<p>Formally, the strategy we implemented in Section (<a href="resampling-stat.html#permut-test-build-up">7.2.1</a>) is a permutation test.</p>
<p>Generally a permutation test is used to test the statistical dependence between two variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. In our example, we had one quantitative and one qualitative but they can be of any kind.</p>
<p>The test statistics can be any measure that captures the dependence.</p>
<p>We assumed that the observations are <strong>identically and independently distributed</strong> (i.i.d). Denoting each observation (a row of the data table) <span class="math inline">\((x_i, y_i)\)</span> with <span class="math inline">\(i=1...n\)</span>. The data generating process is the same for all observations (identicallly distributed). Moreover, the observations are independent. In particular the order of the indexing (the order of the rows of the data table) can be considered arbitrary.</p>
<p>The i.i.d. assumption if often taken in Hypothesis testing. It is however a tricky one. For instance if you have longitudinal data or confounders (hidden groups in the data). In our case, if the measurement of growth was done in separate day for the segregants of distinct genotypes, the i.i.d assumption could have not held. It is important in real applications to question this assumption, and if possible, to address it, for instance by stratifying the data.</p>
<p>The null hypothesis of a permutation test is that the two variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are statistically independent:</p>
<p><span class="math display">\[ H_0: x \perp y\]</span></p>
<p>Hence, under the <span class="math inline">\(H_0\)</span>, the data generation process of <span class="math inline">\(x\)</span> is independent of the one of <span class="math inline">\(y\)</span>. Combined with the <span class="math inline">\(i.i.d\)</span> assumption, this implies that the values of <span class="math inline">\(x_i\)</span> could have occurred in any other order with the very same likelihood.</p>
<p>This gives us a mechanisms to simulate data under the null (Figure <a href="resampling-stat.html#fig:hypothesis-test-overview">7.3</a>).</p>
<p>An exact permutation test considers all possible distinct permutation (See next chapter). With a large number of observations as here (<span class="math inline">\(n=184\)</span>), we can also draw enough random permutations to have decent idea of the distribution of <span class="math inline">\(p(T|H_0)\)</span>.</p>
<p>For a one-sided p-value we do:</p>
<ul>
<li><span class="math inline">\(m\)</span> be the number of random (Monte Carlo) permutations</li>
<li><span class="math inline">\(r = \#\{T^* \geq T_\text{obs}\}\)</span> be the number of these random permutations that produce a test statistic greater than or equal to that calculated for the actual data.</li>
</ul>
<p>Then the estimated one-sided P-value, <span class="math inline">\(\hat P\)</span> is <span class="citation">(<a href="#ref-davison_hinkley_1997" role="doc-biblioref">Davison and Hinkley 1997</a>; <a href="#ref-Phipson2010" role="doc-biblioref">Phipson and Smyth 2010</a>)</span></p>
<p><span class="math display" id="eq:permut-p-val">\[\begin{align}
\hat P = \frac{r+1}{m+1}
\tag{7.1}
\end{align}\]</span></p>
<p>Permutation P-values should never be zero <span class="citation">(<a href="#ref-Phipson2010" role="doc-biblioref">Phipson and Smyth 2010</a>)</span>. Do not use <span class="math inline">\(\frac{r}{m}\)</span> as often done!</p>
<p>In our case, we observed no single permutation with larger test statistics. Hence <span class="math inline">\(r=0\)</span>. We thus get:</p>
<p><span class="math display">\[ \hat P = \frac{1}{1001} \simeq 0.01\]</span>
So, if we assume that the null hypothesis is true, the probability of observing a difference in median growth rates as, or more, extreme as the ones we actually observed, is less than one in one thousand. We would thus need to be quite unlucky to get results like this by chance. So, we reject the null hypothesis and we say that the association between genotype at marker 5211 and growth rates in maltose is statistically significant.</p>
</div>
</div>
<div id="confidence-intervals-quantifying-uncertainty-in-parameter-estimates" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Confidence intervals: Quantifying uncertainty in parameter estimates</h2>
<p>Hypothesis testing is a very effective way to guard us from being fooled by random patterns in our data. But it only answers a very specific question.</p>
<p>For the yeast example, we observed a difference of median growth rates of about 2.2 between yeast strains with different genotypes at marker 5211. Based on our permutation test, we rejected the null hypothesis that growth rate in Maltose is independent of the genotype at marker 5211. In other words, we concluded that the true difference in growth rates is unlikely to be zero. But does that mean that 2.2 is a good estimate of the true difference of median growth rates? How certain are we about this number?</p>
<p>We often face scenarios like this one, where we would like to estimate a certain quantity and report on the uncertainty of this estimate. This framework is called parameter estimation, and it is summarized in the following diagram:</p>
<p><img src="assets/img/lec09-stat-testing/lec10_Parameter-estimation-overview.png" width="800px" /></p>
<p>As before, there is a random process which produced our data, on which we compute summary statistics. But rather than just rejecting a null hypothesis, we now want to <em>infer</em> a parameter from our summary statistics, and also get an idea how precise our inference is. The confidence interval is a method to quantify our uncertainty about a parameter estimate. note that in this scenario we do not need ways of assessing the distribution under a null data generation process, but rather under the actual data generation process.</p>
<div id="repeating-experiments-to-quantify-uncertainty" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Repeating experiments to quantify uncertainty</h3>
<p>We will first show the intuition behind the confidence interval and show how it can be computed in practice. Only then will we formally define it.</p>
<p>Imagine we have an unlimited budget and can repeat the entire yeast experiment 100 times. Every time we follow the same experimental protocol, and every time we compute the difference of median growth rates between yeast strains with different genotypes at marker 5211. This gives us a distribution of parameter estimates (note that, if the null hypothesis is true, this corresponds to the null distribution).</p>
<p>Assume we get the following distribution:</p>
<p><img src="dataviz_book_files/figure-html/lecture-02-305-1.png" width="672" /></p>
<p>We see that many estimates are quite close to the one we measured in our first experiment. However, we also see that we get a range of results.</p>
<p>We do not know the true difference of medians, and in theory any of these estimates could be correct. So one way we could quantify our uncertainty is by reporting the full range of estimates we computed. However, this interval can quickly become very big. If we do the same experiment very often, it is quite plausible that we will have a bad day at some point and, for example, contaminate the samples, leading to an estimate that is very different than the others. We don’t want the size of our interval to be entirely determined by one or two such outliers.</p>
<p>A more robust alternative is to report an interval that covers the central <span class="math inline">\(95\%\)</span> of the values we got:</p>
<p><img src="dataviz_book_files/figure-html/lecture-02-306-1.png" width="672" /></p>
<p>This interval thus covers the estimates derived from 95 of our 100 experiments, and only excludes the 5 most extreme ones. It seems very plausible that the true difference of medians, whatever it is, is somewhere in this interval, unless we got quite unlucky.</p>
</div>
<div id="simulating-repeated-experiments" class="section level3" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Simulating repeated experiments</h3>
<p>The method of repeating experiments is a great way to quantify uncertainty. But in practice, we usually have to work with the data we actually have and cannot just rerun every experiment many times. This would be way too expensive and time consuming.</p>
<p>What we can do, however, is simulate reruns of the experiment by sampling from the data we already have. To this end, the concept of a cumulative distribution function will be useful.</p>
<div id="empirical-distribution" class="section level4" number="7.3.2.1">
<h4><span class="header-section-number">7.3.2.1</span> Empirical distribution</h4>
<p>Consider a random variable <span class="math inline">\(X\)</span> and a random sample of <span class="math inline">\(n\)</span> independent realizations drawn from it: <span class="math inline">\(\{x_1, x_2,...x_n\}\)</span>. The empirical distribution is the distribution that gives equal probability to each of these observations.</p>
<p>A single random draw from the empirical distribution amounts to picking one data point with probability <span class="math inline">\(\frac{1}{n}\)</span>. Independent random draws of any size <span class="math inline">\(m\)</span> are thus equivalent to sampling <strong>with replacement</strong>.</p>
<p>In R this is obtained using the sample function:</p>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="resampling-stat.html#cb497-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb497-2"><a href="resampling-stat.html#cb497-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">20</span>) <span class="co"># 20 random numbers normally distributed </span></span>
<span id="cb497-3"><a href="resampling-stat.html#cb497-3" aria-hidden="true" tabindex="-1"></a>xrnd <span class="ot">&lt;-</span> <span class="fu">sample</span>(x, <span class="dv">15</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>) <span class="co"># 15 random draws from the data in x </span></span>
<span id="cb497-4"><a href="resampling-stat.html#cb497-4" aria-hidden="true" tabindex="-1"></a>xrnd</span></code></pre></div>
<pre><code>##  [1] -1.20807618 -0.19515038 -0.59916772 -0.19515038
##  [5]  0.92552126 -0.19515038  1.10177950  0.74139013
##  [9]  0.01874617 -0.25647839 -0.25647839  0.98744470
## [13] -0.23823356  0.01874617 -1.62667268</code></pre>
<p>A fundamental result is that the empirical distribution converges to the underlying distribution. This is best seen when considering cumulative distribution function. The empirical cumulative distribution function (eCDF) is a step function that jumps up by <span class="math inline">\(1/n\)</span> at each of the <span class="math inline">\(n\)</span> data points.</p>
<p><span class="math display">\[F_n(x) = \frac{1}{n}\sum_{i=1..n}I_{x_i \leq x}\]</span></p>
<p>In R, it is obtained by ecdf().</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb499-1"><a href="resampling-stat.html#cb499-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">ecdf</span>(x))</span></code></pre></div>
<p><img src="dataviz_book_files/figure-html/lecture-02-308-1.png" width="672" /></p>
<p>The eCDF tells us, for any value <span class="math inline">\(x\)</span>, the proportion of observations less than or equal to <span class="math inline">\(x\)</span>. For example, from the ecdf above, we see that about half of the observations are less than or equal to <span class="math inline">\(0\)</span>. This is equivalent to say that the eCDF tells us, for any value <span class="math inline">\(x\)</span>, the probability of one randomly picked observation among <span class="math inline">\(\{x_1, x_2,...x_n\}\)</span> to be less than or equal to <span class="math inline">\(x\)</span>. Hence, the eCDF is nothing else that the cumulative distribution of the process of randomly drawing from <span class="math inline">\(\{x_1, x_2,...x_n\}\)</span>.</p>
<p>The empirical distribution function converges almost surely to the distribution function of <span class="math inline">\(X\)</span>. This means that as <span class="math inline">\(n\)</span> goes to infinity, the empirical distribution and the actual distribution will become more and more alike:</p>
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb500-1"><a href="resampling-stat.html#cb500-1" aria-hidden="true" tabindex="-1"></a>x_small <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">5</span>)</span>
<span id="cb500-2"><a href="resampling-stat.html#cb500-2" aria-hidden="true" tabindex="-1"></a>x_middle <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">20</span>)</span>
<span id="cb500-3"><a href="resampling-stat.html#cb500-3" aria-hidden="true" tabindex="-1"></a>x_big <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb500-4"><a href="resampling-stat.html#cb500-4" aria-hidden="true" tabindex="-1"></a>x_lbl <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;small_n&quot;</span>, <span class="dv">5</span>), <span class="fu">rep</span>(<span class="st">&quot;medium_n&quot;</span>, <span class="dv">20</span>), <span class="fu">rep</span>(<span class="st">&quot;large_n&quot;</span>, <span class="dv">200</span>))</span>
<span id="cb500-5"><a href="resampling-stat.html#cb500-5" aria-hidden="true" tabindex="-1"></a>x_combined <span class="ot">&lt;-</span> <span class="fu">c</span>(x_small, x_middle, x_big)</span>
<span id="cb500-6"><a href="resampling-stat.html#cb500-6" aria-hidden="true" tabindex="-1"></a>dt_ecdf <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">sample_size =</span> x_lbl, <span class="at">x =</span> x_combined)</span>
<span id="cb500-7"><a href="resampling-stat.html#cb500-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dt_ecdf) <span class="sc">+</span> <span class="fu">stat_ecdf</span>(<span class="fu">aes</span>(x, <span class="at">colour =</span> sample_size)) <span class="sc">+</span></span>
<span id="cb500-8"><a href="resampling-stat.html#cb500-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> pnorm) <span class="sc">+</span> </span>
<span id="cb500-9"><a href="resampling-stat.html#cb500-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Fn(x)&quot;</span>)</span></code></pre></div>
<p><img src="dataviz_book_files/figure-html/lecture-02-309-1.png" width="672" /></p>
<p>The implication is that drawing from the empirical distribution is a justified proxy for drawing from the actual underlying distribution. It is more accurate with large sample sizes.</p>
</div>
<div id="case-resampling-bootstrap" class="section level4" number="7.3.2.2">
<h4><span class="header-section-number">7.3.2.2</span> Case resampling bootstrap</h4>
<p>Using this idea of drawing from the empirical distribution function, we can simulate experiments. After all, an experiment is like drawing from the true distribution, so if our empirical distribution is close enough to the true distribution, then drawing from it is comparable to doing a new experiment.</p>
<p>Concretely, we take a sample of size <span class="math inline">\(n\)</span>, with replacement, from our observed data, to make a new dataset. This is called the case resampling bootstrap.</p>
<p>Of course, this “new” data will resemble the old data. But, provided that <span class="math inline">\(n\)</span> is not extremely small, it will almost certainly not be the same. This is because we are sampling with replacement, meaning that we will select some data points several times, and other points may not be selected at all.</p>
<p>Let us perform one bootstrap for the yeast data and recompute the difference of median growth rates:</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="resampling-stat.html#cb501-1" aria-hidden="true" tabindex="-1"></a>dt_resampled <span class="ot">&lt;-</span> </span>
<span id="cb501-2"><a href="resampling-stat.html#cb501-2" aria-hidden="true" tabindex="-1"></a>  dt[<span class="fu">sample</span>(<span class="fu">nrow</span>(dt), <span class="at">replace =</span> <span class="cn">TRUE</span>)]</span>
<span id="cb501-3"><a href="resampling-stat.html#cb501-3" aria-hidden="true" tabindex="-1"></a><span class="fu">diff_median</span>(dt_resampled)</span></code></pre></div>
<pre><code>## [1] 2.666546</code></pre>
<p>As we see, this value is indeed somewhat different from the one we computed from our original sample.</p>
</div>
</div>
<div id="quantifying-uncertainty-using-the-case-resampling-bootstrap" class="section level3" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Quantifying uncertainty using the case resampling bootstrap</h3>
<p>Now let us do <span class="math inline">\(R\)</span> random simulations of the data by case resampling. Each gives a random value for the parameter denoted <span class="math inline">\(T_i^*\)</span>. Let’s rank them by increasing order and denote them:</p>
<p><span class="math display">\[T^*_1 \leq T^*_2 \leq ... \leq T^*_R\]</span>
We can do this for our yeast data and visualize the result as a histogram of parameter estimates.</p>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb503-1"><a href="resampling-stat.html#cb503-1" aria-hidden="true" tabindex="-1"></a><span class="co"># number of random simulations</span></span>
<span id="cb503-2"><a href="resampling-stat.html#cb503-2" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">1000</span> </span>
<span id="cb503-3"><a href="resampling-stat.html#cb503-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb503-4"><a href="resampling-stat.html#cb503-4" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize T_boot with missing values</span></span>
<span id="cb503-5"><a href="resampling-stat.html#cb503-5" aria-hidden="true" tabindex="-1"></a><span class="co"># (safer than with 0&#39;s)</span></span>
<span id="cb503-6"><a href="resampling-stat.html#cb503-6" aria-hidden="true" tabindex="-1"></a>T_bootstrap <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="dv">1000</span>)</span>
<span id="cb503-7"><a href="resampling-stat.html#cb503-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb503-8"><a href="resampling-stat.html#cb503-8" aria-hidden="true" tabindex="-1"></a><span class="co"># iterate for i=1 to R</span></span>
<span id="cb503-9"><a href="resampling-stat.html#cb503-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>R){</span>
<span id="cb503-10"><a href="resampling-stat.html#cb503-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sample the original data with same size with replacement</span></span>
<span id="cb503-11"><a href="resampling-stat.html#cb503-11" aria-hidden="true" tabindex="-1"></a>  dt_boot <span class="ot">&lt;-</span> dt[<span class="fu">sample</span>(<span class="fu">nrow</span>(dt), <span class="at">replace=</span><span class="cn">TRUE</span>)]</span>
<span id="cb503-12"><a href="resampling-stat.html#cb503-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># store the difference of medians in the i-th entry of T_permuted</span></span>
<span id="cb503-13"><a href="resampling-stat.html#cb503-13" aria-hidden="true" tabindex="-1"></a>  T_bootstrap[i] <span class="ot">&lt;-</span> <span class="fu">diff_median</span>(dt_boot)</span>
<span id="cb503-14"><a href="resampling-stat.html#cb503-14" aria-hidden="true" tabindex="-1"></a>} </span></code></pre></div>
<p>The 95% bootstrap percentile confidence interval can now be obtained using the quantiles.</p>
<p>More concretely, we use the same idea as we had in the beginning when we actually repeated experiments: we again try to cover the central <span class="math inline">\((1-\alpha)*100\%\)</span> of the distribution of estimates, where we can choose <span class="math inline">\((1-\alpha)*100\%\)</span> to be bigger or smaller to depending on how conservative we want to be.</p>
<p>This is achieved by using the interval:</p>
<p><span class="math display">\[ ( T^*_{(R+1)\alpha/2}, T^*_{(R+1)(1-\alpha/2)} )\]</span></p>
<p>To get a concrete feeling of what this means, assume <span class="math inline">\(R=99\)</span> and <span class="math inline">\(\alpha=0.1\)</span>. Then, <span class="math inline">\((R+1)\alpha/2 = 5\)</span> and <span class="math inline">\((R+1)(1-\alpha/2) = 95\)</span>. Thus our <span class="math inline">\(90\%\)</span> interval is given by <span class="math inline">\((T^*_{5},T^*_{95})\)</span>, i.e. the interval ranging from the 5-th smallest bootstrap parameter estimate to the 95-th smallest bootstrap parameter estimate. It is nothing else than the interval containing 90% of the bootstrap estimates and with equal fraction of the remaining bootstrap estimates on either side (so-called “equi-tailed”).</p>
<p>In R, we can use the quantile function to compute this. For <span class="math inline">\((1-\alpha)*100\% = 95\%\)</span> interval, we do:</p>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb504-1"><a href="resampling-stat.html#cb504-1" aria-hidden="true" tabindex="-1"></a>conf_int <span class="ot">&lt;-</span> <span class="fu">quantile</span>(T_bootstrap, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb504-2"><a href="resampling-stat.html#cb504-2" aria-hidden="true" tabindex="-1"></a>conf_int</span></code></pre></div>
<pre><code>##    2.5%   97.5% 
## 1.74471 2.93088</code></pre>
<p>The following plot shows the entire distribution along with the observed value and the 95% bootstrap percentile confidence interval.</p>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="resampling-stat.html#cb506-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.table</span>(T_bootstrap), <span class="fu">aes</span>(T_bootstrap)) <span class="sc">+</span></span>
<span id="cb506-2"><a href="resampling-stat.html#cb506-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins=</span><span class="dv">30</span>) <span class="sc">+</span> </span>
<span id="cb506-3"><a href="resampling-stat.html#cb506-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept=</span>T_obs, <span class="at">color =</span> <span class="st">&quot;T_obs&quot;</span>)) <span class="sc">+</span></span>
<span id="cb506-4"><a href="resampling-stat.html#cb506-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept=</span>conf_int[<span class="dv">1</span>], <span class="at">color=</span><span class="st">&quot;CI&quot;</span>), <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb506-5"><a href="resampling-stat.html#cb506-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept=</span>conf_int[<span class="dv">2</span>], <span class="at">color=</span><span class="st">&quot;CI&quot;</span>), <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb506-6"><a href="resampling-stat.html#cb506-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values=</span>cbPalette) <span class="sc">+</span></span>
<span id="cb506-7"><a href="resampling-stat.html#cb506-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;estimated difference of median growth rates&quot;</span>)</span></code></pre></div>
<p><img src="dataviz_book_files/figure-html/lecture-02-313-1.png" width="384" /></p>
</div>
<div id="confidence-intervals-formal-definition" class="section level3" number="7.3.4">
<h3><span class="header-section-number">7.3.4</span> Confidence Intervals: Formal definition</h3>
<p>Let us now define a confidence interval formally.</p>
<p>A <strong>confidence interval</strong> of confidence level <span class="math inline">\(1-\alpha\)</span> for a parameter <span class="math inline">\(\theta\)</span> is an interval <span class="math inline">\(C = (a,b)\)</span>, which would the data generation process be repeated, would contain the parameter with probability <span class="math inline">\(1-\alpha\)</span>, i.e. <span class="math inline">\(p(\theta \in C)=1-\alpha\)</span>. A typical value is <span class="math inline">\(\alpha=0.05\)</span> which leads to 95% confidence intervals.</p>
<p>Note that <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are functions of the data and thus <span class="math inline">\(C\)</span> is the random variable here, not <span class="math inline">\(\theta\)</span>!</p>
<p>To get some intuition for this, consider again the scenario where we repeat the yeast experiment 100 times. But instead of computing one <span class="math inline">\(95\%\)</span> interval from all the experiments, we instead compute a separate <span class="math inline">\(95\%\)</span> interval for each of the experiments (using, for example, the case resampling bootstrap). Then the true difference of medians, whatever it is, will be contained in about 95 of the computed intervals. In other words, it will happen relatively rarely (about 5% of the time) that we get an interval that happens not to include the true difference of medians.</p>
<p>But note carefully what this means. It means that before we do an experiment, we have a 95% chance to end up with an interval that contains the true value. It does not mean that the specific interval we compute after the experiment has been done has a 95% chance of including the true value. This statement would not even make sense. The true value is a fixed number, so either it is in the interval, or it is not. There is no notion of probability there.</p>
<p>It should be noted that the <span class="math inline">\((1-\alpha)\)</span> case resampling bootstrap interval is only an approximate <span class="math inline">\((1-\alpha)\)</span> confidence interval. This means it does not guarantee that <span class="math inline">\(p(\theta \in C)=1-\alpha\)</span>, but only that <span class="math inline">\(p(\theta \in C)\approx1-\alpha\)</span>.</p>
<!-- NB: the only proof I found that the case resampling is a confidence interval assumes the existence of a monotone normalizing transformation. The author adds "an exact normalizing distribution will rarely exist but there may exist approximate normalizing transformations". So, in effect, I am a bit unsure of the theoretical basis of this  -->
<p>There are other ways to compute confidence intervals, which usually require making further assumptions, such as that the data is normally distributed. See Davison AC, Hinkley DV (1997) for an overview.</p>
</div>
<div id="visualizing-the-formal-definition-of-confidence-intervals" class="section level3" number="7.3.5">
<h3><span class="header-section-number">7.3.5</span> Visualizing the formal definition of Confidence Intervals</h3>
<p>To visualize the meaning of this definition, we will now consider an example where we know the true value of the parameter. Specifically we assume that we are trying to use the sample mean as estimate of the true mean of a standard normal distribution. Thus, the true mean is zero.</p>
<p>Firstly, let us run the experiment:</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="resampling-stat.html#cb507-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb507-2"><a href="resampling-stat.html#cb507-2" aria-hidden="true" tabindex="-1"></a>exp_1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">30</span>) <span class="co"># original data (30 values drawn from the standard normal distribution)</span></span></code></pre></div>
<p>Now we compute the sample mean and do a bootstrap resampling:</p>
<div class="sourceCode" id="cb508"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb508-1"><a href="resampling-stat.html#cb508-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute observed sample mean</span></span>
<span id="cb508-2"><a href="resampling-stat.html#cb508-2" aria-hidden="true" tabindex="-1"></a>observed_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(exp_1)</span>
<span id="cb508-3"><a href="resampling-stat.html#cb508-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb508-4"><a href="resampling-stat.html#cb508-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Do bootstrap and compute sample mean for each simulation</span></span>
<span id="cb508-5"><a href="resampling-stat.html#cb508-5" aria-hidden="true" tabindex="-1"></a>boot <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>, <span class="cf">function</span>(i){<span class="fu">sample</span>(exp_1, <span class="dv">30</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)})</span>
<span id="cb508-6"><a href="resampling-stat.html#cb508-6" aria-hidden="true" tabindex="-1"></a>sample_means <span class="ot">&lt;-</span> <span class="fu">sapply</span>(boot, mean)</span></code></pre></div>
<p>This creates a distribution of estimates. We build our <span class="math inline">\(95\%\)</span> case resampling bootstrap confidence interval:</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="resampling-stat.html#cb509-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% C.I. is given by the 2.5% and the 97.5% quantile</span></span>
<span id="cb509-2"><a href="resampling-stat.html#cb509-2" aria-hidden="true" tabindex="-1"></a>conf_int <span class="ot">=</span> <span class="fu">quantile</span>(sample_means, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb509-3"><a href="resampling-stat.html#cb509-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot histogram </span></span>
<span id="cb509-4"><a href="resampling-stat.html#cb509-4" aria-hidden="true" tabindex="-1"></a>bootstrap_tbl <span class="ot">=</span> <span class="fu">data.table</span>(<span class="at">means =</span> sample_means)</span>
<span id="cb509-5"><a href="resampling-stat.html#cb509-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> bootstrap_tbl, <span class="fu">aes</span>(<span class="at">x =</span> means)) <span class="sc">+</span> </span>
<span id="cb509-6"><a href="resampling-stat.html#cb509-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>() <span class="sc">+</span> </span>
<span id="cb509-7"><a href="resampling-stat.html#cb509-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept=</span>observed_mean, <span class="at">color=</span><span class="st">&quot;observed&quot;</span>))  <span class="sc">+</span> </span>
<span id="cb509-8"><a href="resampling-stat.html#cb509-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept=</span><span class="dv">0</span>, <span class="at">color=</span><span class="st">&quot;true&quot;</span>))  <span class="sc">+</span> </span>
<span id="cb509-9"><a href="resampling-stat.html#cb509-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept=</span>conf_int[<span class="dv">1</span>], <span class="at">color=</span><span class="st">&quot;CI&quot;</span>), <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb509-10"><a href="resampling-stat.html#cb509-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept=</span>conf_int[<span class="dv">2</span>], <span class="at">color=</span><span class="st">&quot;CI&quot;</span>), <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb509-11"><a href="resampling-stat.html#cb509-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">name =</span> <span class="st">&quot;Legend&quot;</span>, <span class="at">values =</span> <span class="fu">c</span>(<span class="at">true=</span><span class="st">&quot;black&quot;</span>, <span class="at">observed =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">CI =</span> <span class="st">&quot;red&quot;</span>))</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with
## `binwidth`.</code></pre>
<p><img src="dataviz_book_files/figure-html/lecture-02-316-1.png" width="672" /></p>
<p>We see that our interval covers all but the most extreme estimates (the tails of the distribution). It also covers the true value, which is slightly lower than the observed value.</p>
<p>It now remains to show that this interval keeps what it promises, namely that we capture the true value about <span class="math inline">\(95\%\)</span> of the time if we repeat the “experiment.”</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb511-1"><a href="resampling-stat.html#cb511-1" aria-hidden="true" tabindex="-1"></a>rerun_experiment <span class="ot">&lt;-</span> <span class="cf">function</span>(j) {</span>
<span id="cb511-2"><a href="resampling-stat.html#cb511-2" aria-hidden="true" tabindex="-1"></a>  exp <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">30</span>)</span>
<span id="cb511-3"><a href="resampling-stat.html#cb511-3" aria-hidden="true" tabindex="-1"></a>  boot <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>, <span class="cf">function</span>(i){<span class="fu">sample</span>(exp, <span class="dv">30</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)})</span>
<span id="cb511-4"><a href="resampling-stat.html#cb511-4" aria-hidden="true" tabindex="-1"></a>  sample_means <span class="ot">&lt;-</span> <span class="fu">sapply</span>(boot, mean)</span>
<span id="cb511-5"><a href="resampling-stat.html#cb511-5" aria-hidden="true" tabindex="-1"></a>  conf_int <span class="ot">=</span> <span class="fu">quantile</span>(sample_means, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb511-6"><a href="resampling-stat.html#cb511-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(conf_int)</span>
<span id="cb511-7"><a href="resampling-stat.html#cb511-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb511-8"><a href="resampling-stat.html#cb511-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb511-9"><a href="resampling-stat.html#cb511-9" aria-hidden="true" tabindex="-1"></a>rerun <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>, rerun_experiment)</span></code></pre></div>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="resampling-stat.html#cb512-1" aria-hidden="true" tabindex="-1"></a>intervals <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="fu">t</span>(rerun))</span>
<span id="cb512-2"><a href="resampling-stat.html#cb512-2" aria-hidden="true" tabindex="-1"></a>intervals[, idx <span class="sc">:</span><span class="er">=</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>]</span>
<span id="cb512-3"><a href="resampling-stat.html#cb512-3" aria-hidden="true" tabindex="-1"></a>intervals[, mid <span class="sc">:</span><span class="er">=</span> (<span class="st">`</span><span class="at">97.5%</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">2.5%</span><span class="st">`</span>)<span class="sc">/</span><span class="dv">2</span>]</span>
<span id="cb512-4"><a href="resampling-stat.html#cb512-4" aria-hidden="true" tabindex="-1"></a>intervals[, contains_true <span class="sc">:</span><span class="er">=</span> ((<span class="st">`</span><span class="at">97.5%</span><span class="st">`</span> <span class="sc">&gt;=</span> <span class="dv">0</span>) <span class="sc">&amp;</span> (<span class="st">`</span><span class="at">2.5%</span><span class="st">`</span> <span class="sc">&lt;=</span> <span class="dv">0</span>))]</span>
<span id="cb512-5"><a href="resampling-stat.html#cb512-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> intervals, <span class="fu">aes</span>(mid, idx, <span class="at">color=</span>contains_true)) <span class="sc">+</span> </span>
<span id="cb512-6"><a href="resampling-stat.html#cb512-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">xmin=</span><span class="st">`</span><span class="at">2.5%</span><span class="st">`</span>, <span class="at">xmax=</span><span class="st">`</span><span class="at">97.5%</span><span class="st">`</span>)) <span class="sc">+</span></span>
<span id="cb512-7"><a href="resampling-stat.html#cb512-7" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept=</span><span class="dv">0</span>)) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;estimated mean&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;experiment number&quot;</span>) <span class="sc">+</span> </span>
<span id="cb512-8"><a href="resampling-stat.html#cb512-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color=</span><span class="st">&quot;Error bar contains</span><span class="sc">\n</span><span class="st">true mean&quot;</span>)</span></code></pre></div>
<p><img src="dataviz_book_files/figure-html/lecture-02-318-1.png" width="672" /></p>
<p>This plot shows for each repetition of the experiment the confidence interval we computed. The true mean is at 0, but in every experiment, the estimated mean (or sample mean) and deviates from the true mean. The boundaries of the 95% confidence intervals as well are random variables. They fluctuate from experiment to experiment. We want these confidence intervals to contain the true mean 95% of the time. The confidence intervals which contain the true mean (0, marked by the black line) are in blue, those that do not are in red. We see that most of the time, our interval does indeed capture the true value.</p>
<p>In fact we capture the true value <span class="math inline">\(92\%\)</span> of the time. This is slightly worse than what we expected, but that is not too surprising because the simulation procedure we have used above is approximate. If we use more bootstrap samples, and replicate our experiment more often, we will reach the <span class="math inline">\(95\%\)</span>.</p>
</div>
<div id="hypothesis-testing-with-the-confidence-interval" class="section level3" number="7.3.6">
<h3><span class="header-section-number">7.3.6</span> Hypothesis testing with the Confidence Interval</h3>
<p>It is relatively common in the scientific literature to perform hypothesis tests using the confidence interval. If our null hypothesis is that a given parameter, e.g. a mean, is zero, and our <span class="math inline">\((1-\alpha)*100\%\)</span> confidence interval for this parameter does not include zero, we could say that we reject the null hypothesis at a significance level of <span class="math inline">\(\alpha\)</span>. In that sense, hypothesis tests and confidence intervals are related.</p>
<p>This being said, in this chapter we have used approximate methods to compute <span class="math inline">\(P\)</span>-values and confidence intervals. Thus it need not necessarily be the case that if one of them rejects, the other will too (although, most of the time, they should agree).</p>
<p>In analyses where two groups are compared, as in our yeast example where median growth rates are compared between genotypes, people will often use a different procedure to test hypotheses using the confidence interval. In this procedure, we construct a <span class="math inline">\(95\%\)</span> confidence interval for the median growth rate of each genotype separately. We then reject the null hypothesis if and only if the confidence intervals do not overlap.</p>
<p>It is important to note that this is <em>not</em> the same as rejecting if and only if the confidence interval for the difference of medians does not include zero, even if it may seem so intuitively. In fact, this “overlap” procedure is too conservative, and will fail to reject more often than the confidence level suggests.
In the next chapter, we will give a technical reason for this.</p>
</div>
</div>
<div id="discussion-1" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Discussion</h2>
<p>In this chapter we explored ways to avoid being fooled by randomness. Specifically, we discussed hypothesis testing, which is our go-to method to distinguish statistically significant results from noise, and we discussed confidence intervals, which help us to know how uncertain we are about quantities we estimate from our data.</p>
<p>Cares should be taken though. Many misuses of p-values in the scientific literature have been reported, the most obvious being to repeat an experiments until one finally gets P&lt;0.05 and only report this observation in a publication. See <span class="citation"><a href="#ref-Wasserstein2016" role="doc-biblioref">Wasserstein and Lazar</a> (<a href="#ref-Wasserstein2016" role="doc-biblioref">2016</a>)</span> for an extensive discussion.</p>
<p>We have looked only at resampling strategies: permutation testing as Hypothesis testing when assessing statistical dependence of variables, and case resampling for confidence intervals. Resampling methods have the advantage that they are simple to implement and make little assumptions about the underlying distribution. However, they are compute intensive. We finally noticed that the i.i.d assumption may be violated in practice. Therefore, careful thinking of possible hidden dependencies (such as confounders) shall be done when applying these methods.</p>
<!-- This being said, we are not always fooled randomly. In fact, frequently, we will be fooled *systematically*. This can happen due to **confounding**, which was not addressed in this chapter. Confounding occurs when there is some other variable, which we did not consider in our analysis, which drives our results. -->
<!-- As an example, we might find a statistically significant relationship between the amount of ice cream consumed on a given day and the number of people who receive a sunburn. We could then spend a lot of time interpreting this. Maybe eating ice cream makes people more susceptible to sunburn? Or maybe people who get sunburn are likely to eat ice cream to help get over the pain? But there is a confounder here, namely the season. On a hot summer day, people eat ice cream and get sunburned. On a cold winter day, people do not ice cream and they also do not get sunburned. The statistically significant relationship is explained by this confounder.  -->
<!-- Thus, even if a relationship is statistically significant, this does not mean that it is causal. To assess whether a relationship we observe could be causal, we need to account for confounding, which requires conditioning on further variables. -->
<!-- Another limit that we should keep in mind is that statistical significance does not necessarily imply *practical* importance. If a study says that "there is a statistically significant relationship between drinking coffee and all-cause mortality", it sounds scary. But it makes a big difference whether this means that drinking a cup a day leads to an average life-span reduction of several years, or whether it means that drinking 10 cups a day leads to an average life-span reduction of several days. -->
<!-- Thus, to assess whether a significant trend we observe actually matters in practice, we need to determine the effect size. This will also be discussed in a later chapter.  -->
</div>
<div id="conclusion" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Conclusion</h2>
<p>By now you should be able to:</p>
<ul>
<li>Understand what we mean when we say a result is statistically significant</li>
<li>Understand the terms test statistic, null hypothesis, <span class="math inline">\(P\)</span>-value and confidence interval and explain their purpose</li>
<li>Understand that the <span class="math inline">\(P\)</span>-value is <em>not</em> the probability that the null hypothesis is true</li>
<li>Use permutation to perform Hypothesis testing of associations</li>
<li>Use case resampling to compute bootstrap confidence intervals</li>
</ul>

<!-- Things I am unsure about: -->
<!-- 1) The fixed margins assumption of fisher seems almost always wrong in practice, but we never seem to care -->
<!-- Does it matter? I wrote that "Note that this assumption is often violated in practice, as in the example above where we randomly sampled patients rather than sampling a fixed amount from each subgroup. But Fisher's exact test is nevertheless applied because we usually assume that the margin totals do not contain information about the relationship of interest."  -->
<!-- Is this a correct summary? -->
<!-- 2) I am not 100% sure I understand the distinction of parametric/non-parametric super well. I would be happy if someone could check the section "Parametric and Non-Parametric Tests" to make sure it is correct. -->
<!-- It makes sense in the abstract, but I find it a bit hard to distinguish them in practice. The binomial test is one example. It looks parametric (it assumes that the underlying data is iid bernoulli and the null hypothesis is framed in terms of the bernoulli parameter p) but the sign test is also a binomial test and its definetely nonparametric. So it sort of depends on how you frame it?  -->
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-davison_hinkley_1997" class="csl-entry">
Davison, A. C., and D. V. Hinkley. 1997. <em>Bootstrap Methods and Their Application</em>. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511802843">https://doi.org/10.1017/CBO9780511802843</a>.
</div>
<div id="ref-gagneur2013" class="csl-entry">
Gagneur, Julien, Oliver Stegle, Chenchen Zhu, Petra Jakob, Manu M. Tekkedil, Raeka S. Aiyar, Ann-Kathrin Schuon, Dana Pe’er, and Lars M. Steinmetz. 2013. <span>“Genotype-Environment Interactions Reveal Causal Pathways That Mediate Genetic Effects on Phenotype.”</span> <em>PLOS Genetics</em> 9 (9): 1–10. <a href="https://doi.org/10.1371/journal.pgen.1003803">https://doi.org/10.1371/journal.pgen.1003803</a>.
</div>
<div id="ref-Phipson2010" class="csl-entry">
Phipson, Belinda, and Gordon K Smyth. 2010. <span>“Permutation p-Values Should Never Be Zero: Calculating Exact p-Values When Permutations Are Randomly Drawn.”</span> <em>Statistical Applications in Genetics and Molecular Biology</em> 9 (1). https://doi.org/<a href="https://doi.org/10.2202/1544-6115.1585">https://doi.org/10.2202/1544-6115.1585</a>.
</div>
<div id="ref-Wasserstein2016" class="csl-entry">
Wasserstein, Ronald L., and Nicole A. Lazar. 2016. <span>“The ASA Statement on p-Values: Context, Process, and Purpose.”</span> <em>The American Statistician</em> 70 (2): 129–33. <a href="https://doi.org/10.1080/00031305.2016.1154108">https://doi.org/10.1080/00031305.2016.1154108</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="13">
<li id="fn13"><p><a href="https://en.wikipedia.org/wiki/Chromosomal_crossover" class="uri">https://en.wikipedia.org/wiki/Chromosomal_crossover</a><a href="resampling-stat.html#fnref13" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="graph-supported-hypos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analytical-stat.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
