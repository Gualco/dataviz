<!DOCTYPE html>
<html>
<head>
  <title>Data Analysis and Visualization</title>
  <meta charset="utf-8">
  <meta name="description" content="Data Analysis and Visualization">
  <meta name="author" content="Julien Gagneur, Jan Krumsiek">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  <link rel=stylesheet href="libraries/widgets/bootstrap/css/bootstrap.css"></link>
<link rel=stylesheet href="libraries/widgets/quiz/css/demo.css"></link>
<link rel=stylesheet href="./assets/css/custom.css"></link>

  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  <script src="libraries/widgets/highcharts/js/jquery-1.9.1.min.js"></script>
<script src="libraries/widgets/highcharts/js/highcharts.js"></script>
<script src="libraries/widgets/highcharts/js/highcharts-more.js"></script>
<script src="libraries/widgets/highcharts/js/exporting.js"></script>


</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
      <slide class="nobackground">
    <article class="flexbox vcenter">
      <span>
        <img width='300px' src="assets/img/title.jpg">
      </span>
    </article>
  </slide>
    <slide class="title-slide segue nobackground">
  <hgroup class="auto-fadein">
    <h1>Data Analysis and Visualization</h1>
    <h2>Classification</h2>
    <p>Julien Gagneur, Jan Krumsiek<br/></p>
  </hgroup>
  <article></article>  
</slide>
    

    <!-- SLIDES -->
    <slide class="" id="slide-1" style="background:;">
  <article data-timings="">
    <!-- Center image on slide --> 

<script 
src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script> <script 
type='text/javascript'> $(function() { $("p:has(img)").addClass('centered'); });
</script>

<!-- setwd('./lectures/') -->

<!-- START LECTURE -->

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-2" style="background:;">
  <hgroup>
    <h2>Motivation</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>One application of linear regression is the prediction of the value of the response \(y\) for new values of the predictors \(x_1,...,x_p\)</p></li>
<li><p>In regression, \(y\) is a continuous real value</p></li>
<li><p>In many prediction applications \(y\) is a category. Examples:</p>

<ul>
<li>diagnostic (have a disease or not)</li>
<li>spam email, not spam email</li>
<li>Handwritten digit recognition (0,1,...,9)</li>
<li>Speech recognition (words)</li>
</ul></li>
<li><p>Prediction tasks when the response is a category are called classification tasks</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>Overview</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>Notations and definitions</p></li>
<li><p>Logistic regression</p></li>
<li><p>Other classifiers: k-NN, SVM, decision trees, random forest and neural networks</p></li>
<li><p>Assessing classifiers</p></li>
<li><p>Training classifiers robustly</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Notation</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>We use the machine learning nomenclature:</p>

<ul>
<li>\(y\) denotes the <em>outcome</em> (or response) we want to predict </li>
<li>\(x_1, \dots, x_p\) denote the <em>features</em> that we will use to predict the outcome.</li>
</ul></li>
<li><p>Goal: Build an algorithm that takes feature values as input and returns a prediction for the outcome when we don&#39;t know the outcome.</p></li>
<li><p>The machine learning approach is to <em>train</em> an algorithm using a dataset for which we do know the outcome, and then apply this algorithm in the future to make a prediction when we don&#39;t know the outcome.</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Prediction</h2>
  </hgroup>
  <article data-timings="">
    <p>We have a series of features and an unknown outcome we want to predict:</p>

<table><thead>
<tr>
<th align="center">outcome</th>
<th align="center">feature_1</th>
<th align="center">feature_2</th>
<th align="center">feature_3</th>
<th align="center">feature_4</th>
<th align="center">feature_5</th>
</tr>
</thead><tbody>
<tr>
<td align="center">?</td>
<td align="center">\(x_1\)</td>
<td align="center">\(x_2\)</td>
<td align="center">\(x_3\)</td>
<td align="center">\(x_4\)</td>
<td align="center">\(x_5\)</td>
</tr>
</tbody></table>

<p>To <em>build a model</em> that provides a prediction for any set of observed values \(x_1, x_2, \dots x_5\), we collect data for which we know the outcome:</p>

<table><thead>
<tr>
<th align="left">outcome</th>
<th align="left">feature_1</th>
<th align="left">feature_2</th>
<th align="left">feature_3</th>
<th align="left">feature_4</th>
<th align="left">feature_5</th>
</tr>
</thead><tbody>
<tr>
<td align="left">\(y_{1}\)</td>
<td align="left">\(x_{1,1}\)</td>
<td align="left">\(x_{1,2}\)</td>
<td align="left">\(x_{1,3}\)</td>
<td align="left">\(x_{1,4}\)</td>
<td align="left">\(x_{1,5}\)</td>
</tr>
<tr>
<td align="left">\(y_{2}\)</td>
<td align="left">\(x_{2,1}\)</td>
<td align="left">\(x_{2,2}\)</td>
<td align="left">\(x_{2,3}\)</td>
<td align="left">\(x_{2,4}\)</td>
<td align="left">\(x_{2,5}\)</td>
</tr>
<tr>
<td align="left">\(y_{3}\)</td>
<td align="left">\(x_{3,1}\)</td>
<td align="left">\(x_{3,2}\)</td>
<td align="left">\(x_{3,3}\)</td>
<td align="left">\(x_{3,4}\)</td>
<td align="left">\(x_{3,5}\)</td>
</tr>
<tr>
<td align="left">\(y_{4}\)</td>
<td align="left">\(x_{4,1}\)</td>
<td align="left">\(x_{4,2}\)</td>
<td align="left">\(x_{4,3}\)</td>
<td align="left">\(x_{4,4}\)</td>
<td align="left">\(x_{4,5}\)</td>
</tr>
<tr>
<td align="left">\(y_{5}\)</td>
<td align="left">\(x_{5,1}\)</td>
<td align="left">\(x_{5,2}\)</td>
<td align="left">\(x_{5,3}\)</td>
<td align="left">\(x_{5,4}\)</td>
<td align="left">\(x_{5,5}\)</td>
</tr>
<tr>
<td align="left">\(y_{6}\)</td>
<td align="left">\(x_{6,1}\)</td>
<td align="left">\(x_{6,2}\)</td>
<td align="left">\(x_{6,3}\)</td>
<td align="left">\(x_{6,4}\)</td>
<td align="left">\(x_{6,5}\)</td>
</tr>
<tr>
<td align="left">\(y_{7}\)</td>
<td align="left">\(x_{7,1}\)</td>
<td align="left">\(x_{7,2}\)</td>
<td align="left">\(x_{7,3}\)</td>
<td align="left">\(x_{7,4}\)</td>
<td align="left">\(x_{7,5}\)</td>
</tr>
<tr>
<td align="left">\(y_{8}\)</td>
<td align="left">\(x_{8,1}\)</td>
<td align="left">\(x_{8,2}\)</td>
<td align="left">\(x_{8,3}\)</td>
<td align="left">\(x_{8,4}\)</td>
<td align="left">\(x_{8,5}\)</td>
</tr>
<tr>
<td align="left">\(y_{9}\)</td>
<td align="left">\(x_{9,1}\)</td>
<td align="left">\(x_{9,2}\)</td>
<td align="left">\(x_{9,3}\)</td>
<td align="left">\(x_{9,4}\)</td>
<td align="left">\(x_{9,5}\)</td>
</tr>
<tr>
<td align="left">\(y_{10}\)</td>
<td align="left">\(x_{10,1}\)</td>
<td align="left">\(x_{10,2}\)</td>
<td align="left">\(x_{10,3}\)</td>
<td align="left">\(x_{10,4}\)</td>
<td align="left">\(x_{10,5}\)</td>
</tr>
</tbody></table>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-6" style="background:;">
  <hgroup>
    <h2>Classification</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>A <em>classification</em> is a prediction task with a categorical outcome.</p></li>
<li><p>A <em>binary classification</em> is a prediction task with a binary outcome.</p></li>
<li><p>Here we will focus on binary classification.</p></li>
<li><p>We denote \(k=0,1\) the two classes.</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-7" style="background:;">
  <hgroup>
    <h2>A univariate example: predicting sex given the height.</h2>
  </hgroup>
  <article data-timings="">
    <p>The <code>heights</code> dataset of the <code>dslabs</code> package :</p>

<pre><code class="r">heights &lt;- as.data.table(heights)
heights[, y:=as.numeric(sex == &quot;Female&quot;)]
heights
</code></pre>

<pre><code>##          sex   height y
##    1:   Male 75.00000 0
##    2:   Male 70.00000 0
##    3:   Male 68.00000 0
##    4:   Male 74.00000 0
##    5:   Male 61.00000 0
##   ---                  
## 1046: Female 69.00000 1
## 1047:   Male 69.00000 0
## 1048:   Male 63.38583 0
## 1049:   Male 66.00000 0
## 1050:   Male 66.00000 0
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-8" style="background:;">
  <hgroup>
    <h2>Linear regression is not appropriate for classification</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">lm_fit0 &lt;- lm(y~height, data=heights)
ggplot(heights, aes(height, y)) + geom_point() + geom_abline(intercept = lm_fit0$coef[1], slope = lm_fit0$coef[2])
</code></pre>

<p><img src="assets/fig/unnamed-chunk-5-1.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="500px" height="400px" /></p>

<ul>
<li>We need to step back and consider a different modeling approach for categorical responses.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-9" style="background:;">
  <hgroup>
    <h2>Linear regression predicts the expected values</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We denote the density of the normal distribution with mean \(\mu\) and variance \(\sigma^2\) as:
\[N (x|\mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp(-\frac{(x-\mu)^2}{2 \sigma^2})\]</li>
</ul>

<ul class = "build incremental">
<li>We have introduced linear regression with the following model:
\[
\begin{array}
\\
y_i &= \beta_0 + \sum_{j=1}^p \beta_j x_{ij}  + \epsilon_i \\
p(\epsilon_i) &= N(\epsilon_i| 0, \sigma^2)
\end{array}
\] </li>
<li><p>This is equivalent to write:
\[
\begin{array}
\\
p(y_i | x_i) &= N(y_i | \mu_i, \sigma^2) \\
\mu_i &= \beta_0 + \sum_{j=1}^p \beta_j x_{ij} 
\end{array}
\] </p></li>
<li><p>Hence, linear regression models \(\mu_i := E(y_i|x_{i1},...x_{ip})\), the <em>conditional</em> <em>expectation</em> of the outcome conditioned on the features, as a linear combination of the features. </p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-10" style="background:;">
  <hgroup>
    <h2>Logistic regression predicts the expected values</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Logistic regression models the conditional expectation of the outcome conditioned on the features.</li>
</ul>

<ul class = "build incremental">
<li><p>For a binary outcome \(y \in \{0,1\}\), the expectation \(\mu\) is the probability of class 1.</p></li>
<li><p>Modeling a probability with a linear function is not ideal because you can make predictions <0 or >1. Here is a linear fit to the proportion of women vs. height in the <code>heights</code> dataset of the <code>dslabs</code> package :
<img src="assets/fig/unnamed-chunk-6-1.png" title="plot of chunk unnamed-chunk-6" alt="plot of chunk unnamed-chunk-6" width="500px" height="400px" /></p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-11" style="background:;">
  <hgroup>
    <h2>The logistic function maps real numbers to the [0,1] interval</h2>
  </hgroup>
  <article data-timings="">
    <p>The logistic function \(\sigma (t)\) is defined as follows:</p>

<p>\[\sigma (t) = \frac{1}{1+e^{-t}}\]</p>

<p><img src="assets/fig/unnamed-chunk-7-1.png" title="plot of chunk unnamed-chunk-7" alt="plot of chunk unnamed-chunk-7" width="500px" height="400px" /></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-12" style="background:;">
  <hgroup>
    <h2>The logistic regression</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>We can use the logistic function to map linear combinations of the features to the [0,1] interval. A logistic regression models:
\[
\begin{array}
\\
p(y_i | x_i) &= \mu_i \\
\mu_i &= \sigma(\beta_0 + \sum_{j=1}^p \beta_j x_{ij}) 
\end{array}
\] </li>
</ul>

<ul class = "build incremental">
<li><p>An alternative approach is to use the inverse function of the sigmoid, the <em>logit</em> function:
\[
\operatorname{logit}(x) = \log(\frac{x}{1-x})
\]</p></li>
<li><p>We then write:
\[
\begin{array}
\\
& p(y_i | x_i) = \mu_i \\
& \operatorname{logit}(\mu_i) = \eta_i = \beta_0 + \sum_{j=1}^p \beta_j x_{ij} 
\end{array}
\] </p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-13" style="background:;">
  <hgroup>
    <h2>The logistic regression</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>Here are the predicted values using logistic regression (red) compared to a linear regression of the proportions (black). It fits better the data and fixes the negative probabilities issue.</li>
</ul>

<p><img src="assets/fig/unnamed-chunk-8-1.png" title="plot of chunk unnamed-chunk-8" alt="plot of chunk unnamed-chunk-8" width="500px" height="400px" /></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-14" style="background:;">
  <hgroup>
    <h2>Classification with logistic regression</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>The logistic regression predicts a probability. Therefore, it conveys some uncertainty in the prediction.</p></li>
<li><p>Hard classification is usually performed by the following, simple rule:</p></li>
</ul>

<p>If \(\mu>0.5\) (or equivalently \(\eta>0\)), predict class 1, else predict class 0.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-15" style="background:;">
  <hgroup>
    <h2>Logistic regression as a generalized linear model</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>Logistic regression is one instance of generalized linear models, which all exploit the same idea:</p>

<ul>
<li>1. A probability distribution from the exponential family.</li>
<li>2. A linear predictor \(\eta = \mathbf{X}\boldsymbol{\beta}\) .</li>
<li>3. A link function \(g\) such that \(\text{E}(y) = \mu = g^{-1}(\eta)\)</li>
</ul></li>
<li><p>Popular examples are Linear regression, logistic regression, Poisson regression, and Gamma regression</p></li>
<li><p>The inverse of the <em>link</em> function is called the <em>activation</em> function. For logistic regression, the activation function is the sigmoid and the link function is the logit.</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-16" style="background:;">
  <hgroup>
    <h2>Logistic regression with R</h2>
  </hgroup>
  <article data-timings="">
    <p>Here is the <code>heights</code> dataset:</p>

<pre><code class="r">heights &lt;- as.data.table(heights)
heights[,y:=as.numeric(sex == &quot;Female&quot;)]
heights
</code></pre>

<pre><code>##          sex   height y
##    1:   Male 75.00000 0
##    2:   Male 70.00000 0
##    3:   Male 68.00000 0
##    4:   Male 74.00000 0
##    5:   Male 61.00000 0
##   ---                  
## 1046: Female 69.00000 1
## 1047:   Male 69.00000 0
## 1048:   Male 63.38583 0
## 1049:   Male 66.00000 0
## 1050:   Male 66.00000 0
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-17" style="background:;">
  <hgroup>
    <h2>Logistic regression with R</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>In R, you can fit a logistic regression using the <code>glm</code> function (for generalized linear model).</li>
</ul>

<pre><code class="r">logistic_fit &lt;- glm(y ~ height, data=heights, family = &quot;binomial&quot;)
logistic_fit
</code></pre>

<pre><code>## 
## Call:  glm(formula = y ~ height, family = &quot;binomial&quot;, data = heights)
## 
## Coefficients:
## (Intercept)       height  
##     21.1472      -0.3327  
## 
## Degrees of Freedom: 1049 Total (i.e. Null);  1048 Residual
## Null Deviance:       1124 
## Residual Deviance: 892.5     AIC: 896.5
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-18" style="background:;">
  <hgroup>
    <h2>Logistic regression with R</h2>
  </hgroup>
  <article data-timings="">
    <p>The fitted model can be applied to data (seen or unseen) using <code>predict()</code>. By default it returns the linear predictor \(\eta\). Use <code>type=&#39;response&#39;</code> to have the predicted probabilities:</p>

<pre><code class="r">heights[, mu_hat := predict(logistic_fit, heights, type=&quot;response&quot;)]
heights
</code></pre>

<pre><code>##          sex   height y     mu_hat
##    1:   Male 75.00000 0 0.02176993
##    2:   Male 70.00000 0 0.10510737
##    3:   Male 68.00000 0 0.18598336
##    4:   Male 74.00000 0 0.03010441
##    5:   Male 61.00000 0 0.70110560
##   ---                             
## 1046: Female 69.00000 1 0.14075631
## 1047:   Male 69.00000 0 0.14075631
## 1048:   Male 63.38583 0 0.51469737
## 1049:   Male 66.00000 0 0.30769321
## 1050:   Male 66.00000 0 0.30769321
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-19" style="background:;">
  <hgroup>
    <h2>Odds and odds ratios</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>The <em>odds</em> for a binary variable \(y\) are defined as \(\frac{p(y)}{1-p(y)}\). For instance the odds for someone to be a woman is 238 / 812 = 0.3 in the <code>heights</code> dataset.</li>
</ul>

<pre><code class="r">table(heights$sex)
</code></pre>

<pre><code>## 
## Female   Male 
##    238    812
</code></pre>

<ul>
<li>The <em>odds</em> <em>ratio</em> is the ratio of the odds of \(y\) with some condition and the odds of \(y\) without the condition. For instance, the odds ratio for someone to be a woman given the height is shorter than 70 inches (1.78 m) is (222/420) / (16/392) = 12.95. </li>
</ul>

<pre><code class="r">table(heights$sex, shorter_70 = heights$height&lt;70)
</code></pre>

<pre><code>##         shorter_70
##          FALSE TRUE
##   Female    16  222
##   Male     392  420
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-20" style="background:;">
  <hgroup>
    <h2>Coefficients of the logistic regression</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>The \(\beta\) values from logistic regression are log odds ratios, given that all other variables are fixed. Odds ratios can thus be obtained by applying exp().</li>
</ul>

<pre><code class="r">coef(logistic_fit)
</code></pre>

<pre><code>## (Intercept)      height 
##  21.1471969  -0.3326988
</code></pre>

<pre><code class="r">OR_height &lt;- exp(coef(logistic_fit)[2])
OR_height
</code></pre>

<pre><code>##    height 
## 0.7169861
</code></pre>

<ul>
<li>In this case, an increase by one inch is associated with a 0.72 fold-change of the odds.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-21" style="background:;">
  <hgroup>
    <h2>Effects on probabilities</h2>
  </hgroup>
  <article data-timings="">
    <p>\[
p(y) = \frac{odds}{1+odds}
\]</p>

<ul>
<li><p>(A) Starting with 1:1 odds, p=50%, ~63.5 inch., 1-inch increase leads to odds of 0.72:1 odds, i.e. p=42%.</p></li>
<li><p>(B) Starting with 1:9 odds, p=10%, ~70 inch., 1-inch increase leads to odds 0.72*1:9, i.e. p=7.4%.</p></li>
</ul>

<p><img src="./assets/img/lec13_odds-ratio.png" title="plot of chunk unnamed-chunk-15" alt="plot of chunk unnamed-chunk-15" width="475px" height="400px" /></p>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='NA'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='Motivation'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='Overview'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Notation'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='Prediction'>
         5
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=6 title='Classification'>
         6
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=7 title='A univariate example: predicting sex given the height.'>
         7
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=8 title='Linear regression is not appropriate for classification'>
         8
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=9 title='Linear regression predicts the expected values'>
         9
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=10 title='Logistic regression predicts the expected values'>
         10
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=11 title='The logistic function maps real numbers to the [0,1] interval'>
         11
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=12 title='The logistic regression'>
         12
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=13 title='The logistic regression'>
         13
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=14 title='Classification with logistic regression'>
         14
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=15 title='Logistic regression as a generalized linear model'>
         15
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=16 title='Logistic regression with R'>
         16
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=17 title='Logistic regression with R'>
         17
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=18 title='Logistic regression with R'>
         18
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=19 title='Odds and odds ratios'>
         19
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=20 title='Coefficients of the logistic regression'>
         20
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=21 title='Effects on probabilities'>
         21
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  <script src="libraries/widgets/bootstrap/js/bootstrap.min.js"></script>
<script src="libraries/widgets/bootstrap/js/bootbox.min.js"></script>
<script src="libraries/widgets/quiz/js/jquery.quiz.js"></script>
<script src="libraries/widgets/quiz/js/mustache.min.js"></script>
<script src="libraries/widgets/quiz/js/quiz-app.js"></script>

  <!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<script>  
  $(function (){ 
    $("#example").popover(); 
    $("[rel='tooltip']").tooltip(); 
  });  
  </script>  
  
  <!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>